{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final TESS Transit Classification — Optimized for Extreme Class Imbalance\n",
        "\n",
        "This notebook converts and expands the provided Python script into a fully documented, didactic, and **step-by-step** workflow.\n",
        "We train a 1D CNN to classify TESS light curves into *transit* (planet candidate) vs *non-transit* under **severe class imbalance**.\n",
        "\n",
        "**Key strategies covered:**\n",
        "\n",
        "- **Balanced augmentation** (equal samples per class) to mitigate imbalance during training.  \n",
        "- **Focal loss** (tunable `gamma` and `alpha`) to emphasize hard examples and rare positives.  \n",
        "- **Threshold optimization** using **Youden’s J** from the ROC curve (don’t use the default 0.5).  \n",
        "- **Simplified CNN architecture** to reduce overfitting.  \n",
        "- **AUC-centric monitoring** with early stopping and LR scheduling.\n",
        "\n",
        "> **What you’ll learn**\n",
        ">\n",
        "> 1. Why balanced training batches help under extreme imbalance.  \n",
        "> 2. How focal loss reshapes the gradient to focus on hard/rare samples.  \n",
        "> 3. How to pick a **data-driven** decision threshold that best trades off TPR/FPR.  \n",
        "> 4. How to evaluate with AUC-ROC rather than accuracy (which can be misleading).  \n",
        "> 5. How to visualize confusion matrices and sample light curves with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prerequisites & Data\n",
        "\n",
        "**Dependencies** (install if needed):\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn matplotlib tensorflow\n",
        "```\n",
        "\n",
        "> We intentionally avoid additional plotting libraries to keep dependencies compact.  \n",
        "> If you already have a working scientific Python/TensorFlow stack, you can skip installations.\n",
        "\n",
        "**Expected dataset**: a CSV file named **`tess_data.csv`** in the working directory with:\n",
        "\n",
        "- **Light-curve samples**: `flux_0000, flux_0001, ..., flux_0999` (or up to `n_bins-1`)  \n",
        "- **Flux uncertainties**: `flux_err_0000, ..., flux_err_0999`  \n",
        "- **Label**: `label` (0 = Non-Planet, 1 = Planet)  \n",
        "- **Metadata** (used for plots/titles): `toi_name, tic, disp, period_d, t0_bjd, dur_hr, sector`\n",
        "\n",
        "You can change the filename or number of bins via parameters in the **Data Loading** section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "Set up imports, suppress noisy warnings, and fix seeds for reproducibility.  \n",
        "(Exact reproducibility on GPUs may still vary across hardware/driver versions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "883a4745",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting working directory to:  /home/ubuntu/comp_astro_25/notebook/machine_learning\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 18:12:21.916970: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-04 18:12:21.964269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FINAL TESS CLASSIFICATION\n",
            "======================================================================\n",
            "TF version: 2.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 18:12:22.955971: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-12-04 18:12:23.111441: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import IPython\n",
        "    working_directory = \"/\".join(\n",
        "            IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]\n",
        "        )\n",
        "    print(\"Setting working directory to: \", working_directory)\n",
        "    print(os.chdir(working_directory))\n",
        "except Exception as e:\n",
        "    print(\"It was impossible to set your directory as the current one because of the following message\")\n",
        "    print(e)\n",
        "    print(\"The working directory is: \", os.getcwd())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL TESS CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Optional: make TF less eager to pre-allocate all GPU memory (if using GPU)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    if gpus:\n",
        "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
        "except Exception as e:\n",
        "    print(\"GPU setup note:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201e4a1",
      "metadata": {},
      "source": [
        "## 3. Focal Loss (for severe imbalance)\n",
        "\n",
        "**Why focal loss?** With extreme imbalance, the model can get “lazy”—it learns to do well by focusing on the majority class.  \n",
        "Focal loss down-weights *easy* examples and concentrates gradient on *hard* ones by adding a modulating factor \\((1 - p_t)^\\gamma\\).  \n",
        "We also use class weighting via \\(\\alpha\\) to up-weight the rare positive class.\n",
        "\n",
        "- **`gamma`** (focusing parameter): higher values put more emphasis on hard examples.  \n",
        "- **`alpha`** (class weight): weight for positive class (1); negative class gets \\(1 - \\alpha\\).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b3c15b",
      "metadata": {},
      "source": [
        " mahdis : by this i noticed we now want to balance it now regullary which trats datas equally. here we are focued on datas which need more attention. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2de8e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "def focal_loss(gamma=2.5, alpha=0.75):\n",
        "    \"\"\"Focal loss optimized for severe imbalance (binary).\"\"\"\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        \n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_factor = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_factor * K.pow(1 - pt, gamma)\n",
        "        bce = -K.log(pt)\n",
        "        return K.mean(focal_weight * bce)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "\n",
        "## mahdis :\n",
        "## gamma = 2.5 means strong focus on hard examples\n",
        "\n",
        "## alpha = 0.75 means more weight on positive \n",
        "## by adding alph we say to our model that when you make a mistake on positive class it count more than negative class. so try to train more on positive class\n",
        "\n",
        "## we fixed the loss function by adding initial parameter : epsilon to avoid log(0) situation\n",
        "## means  we force y_pred to be in range [epsilon, 1-epsilon]\n",
        "\n",
        "## by pt we change 0, 1 classification to y_pred and 1-y_pred\n",
        "## and update alpha_factor and focal_weight accordingly\n",
        "\n",
        "## by return we get : average (alph * (1-pt)^gamma / log(pt) )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ae786d",
      "metadata": {},
      "source": [
        "## 4. Balanced Augmentation\n",
        "\n",
        "We **balance the training set** to a fixed number of samples per class.  \n",
        "If a class has too few samples, we create augmented variants (noise, scale, shift, combo).  \n",
        "This prevents the model from being swamped by the majority class during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "24800de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_balanced_dataset(X, y, samples_per_class=400):\n",
        "    \"\"\"Create a perfectly balanced dataset via lightweight augmentations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING BALANCED DATASET\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    X_class0 = X[y == 0]\n",
        "    X_class1 = X[y == 1]\n",
        "    \n",
        "    print(f\"Original - Class 0: {len(X_class0)}, Class 1: {len(X_class1)}\")\n",
        "    \n",
        "    def augment_to_target(X_orig, n_target):\n",
        "        if len(X_orig) >= n_target:\n",
        "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
        "            return X_orig[idx]\n",
        "        \n",
        "        X_result = [X_orig]\n",
        "        while len(np.vstack(X_result)) < n_target:\n",
        "            # number we still need (cap to avoid oversampling too big chunks)\n",
        "            n_needed = n_target - len(np.vstack(X_result))\n",
        "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
        "            \n",
        "            aug_type = np.random.rand()\n",
        "            if aug_type < 0.25:\n",
        "                # Additive Gaussian noise\n",
        "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
        "            elif aug_type < 0.5:\n",
        "                # Multiplicative scaling\n",
        "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
        "                X_aug = X_orig[idx] * scale\n",
        "            elif aug_type < 0.75:\n",
        "                # Circular shift (time shift)\n",
        "                shifts = np.random.randint(-20, 20, len(idx))\n",
        "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
        "            else:\n",
        "                # Mild combo: small scale + small noise\n",
        "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
        "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
        "            \n",
        "            X_result.append(X_aug)\n",
        "        \n",
        "        X_final = np.vstack(X_result)\n",
        "        return X_final[:n_target]\n",
        "    \n",
        "    X0_bal = augment_to_target(X_class0, samples_per_class)\n",
        "    X1_bal = augment_to_target(X_class1, samples_per_class)\n",
        "    \n",
        "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
        "    \n",
        "    X_balanced = np.vstack([X0_bal, X1_bal])\n",
        "    y_balanced = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
        "    \n",
        "    # Shuffle\n",
        "    idx = np.arange(len(X_balanced))\n",
        "    np.random.shuffle(idx)\n",
        "    \n",
        "    return X_balanced[idx], y_balanced[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34555fb8",
      "metadata": {},
      "source": [
        "## 5. Data Loading, Splitting & Standardization\n",
        "\n",
        "We split **before** augmentation (to avoid leakage), then **balance only the training split**.  \n",
        "We standardize the flux (zero mean / unit variance) using statistics from the training set only.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Error bars `X_err` are **not** standardized (kept in their original scale).  \n",
        "- We keep the **test metadata** to produce nicer titles in the sample light-curve plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45df1a84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(csv_path='tess_data.csv', n_bins=1000):\n",
        "    \"\"\"Load CSV, split, balance train set, and standardize features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    ## Load data\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Dataset: {df.shape[0]} samples\")\n",
        "    \n",
        "\n",
        "    ## Extract features and labels (x = light curve fluxes , x_err = flux errors, y = labels (planet , non-planet))\n",
        "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
        "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
        "    X = df[flux_cols].values\n",
        "    X_err = df[flux_err_cols].values\n",
        "    y = df['label'].values\n",
        "    \n",
        "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
        "    metadata = df[metadata_cols]\n",
        "    \n",
        "    print(\"\\nOriginal distribution:\")\n",
        "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
        "    if (y==0).sum() > 0:\n",
        "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
        "    \n",
        "    # Train/test split (keep errors aligned; stratify to preserve class ratio)\n",
        "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
        "        X, y, X_err, np.arange(len(y)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nInitial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    \n",
        "    # Balance training set\n",
        "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=350)\n",
        "    \n",
        "    # Standardize (fit on train, apply to test)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STANDARDIZATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
        "    print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
        "    \n",
        "    # Reshape for Conv1D: (samples, timesteps, channels)\n",
        "    X_train = X_train.reshape(-1, n_bins, 1)\n",
        "    X_test = X_test.reshape(-1, n_bins, 1)\n",
        "    \n",
        "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\nFinal - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "    print(f\"Train dist: 0={( y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
        "    \n",
        "    # Return standardized test for model input, but also return the standardized\n",
        "    # copy (X_test_orig) so we can inverse-transform for plotting with error bars.\n",
        "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e4e6b5",
      "metadata": {},
      "source": [
        "## 6. A Simpler 1D CNN (to curb overfitting)\n",
        "\n",
        "A compact ConvNet with **BatchNorm**, **Dropout**, and **Global Average Pooling** is often enough for\n",
        "noisy, small-ish 1D signals. We also add mild L2 on the dense layers. The goal is a strong baseline\n",
        "that generalizes well, not a gigantic model that memorizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c42e5a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_simple_cnn(n_bins=1000):\n",
        "    \"\"\"Simpler CNN to prevent overfitting on small datasets.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING SIMPLIFIED CNN\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "        \n",
        "        # Feature extraction\n",
        "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.4),\n",
        "        \n",
        "        # Classification head\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        \n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "    print(\"\\nUsing Focal Loss (gamma=2.5, alpha=0.75)\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28417447",
      "metadata": {},
      "source": [
        "## 7. Training with AUC Monitoring, Early Stopping & LR Scheduling\n",
        "\n",
        "We monitor **validation AUC** (not accuracy) and:\n",
        "\n",
        "- **EarlyStopping** on `val_auc` with patience to stop when progress stalls.  \n",
        "- **ReduceLROnPlateau** to gently lower the LR when AUC plateaus.  \n",
        "- **ModelCheckpoint** to persist the best model by AUC.\n",
        "\n",
        "> Tip: If your dataset is *very* small, increase dropout and/or reduce dense layers further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "799553e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
        "    \"\"\"Train the model with AUC-centric callbacks.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=8,\n",
        "            min_lr=1e-7,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model_final.keras',\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fd997b",
      "metadata": {},
      "source": [
        "## 8. Evaluation with **Optimal Threshold** (don’t default to 0.5)\n",
        "\n",
        "The default threshold (0.5) is rarely optimal with imbalanced data.  \n",
        "We compute ROC, then choose the threshold that maximizes **Youden’s J** (\\(\\mathrm{TPR} - \\mathrm{FPR}\\)).\n",
        "We report both the default and the optimal settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b85e7698",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
        "    \"\"\"Find an optimal threshold from ROC (Youden's J) and evaluate.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    \n",
        "    # Youden's J statistic\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    \n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (default=0.5)\")\n",
        "    print(f\"  At this threshold: TPR={tpr[optimal_idx]:.4f}, FPR={fpr[optimal_idx]:.4f}\")\n",
        "    \n",
        "    # Predictions with optimal vs default thresholds\n",
        "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
        "    \n",
        "    # Metrics\n",
        "    acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
        "    acc_default = accuracy_score(y_test, y_pred_default)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    \n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  Accuracy (default threshold=0.5): {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
        "    print(f\"  Accuracy (optimal threshold={optimal_threshold:.4f}): {acc_optimal:.4f} ({acc_optimal*100:.2f}%)\")\n",
        "    \n",
        "    print(\"\\nWith optimal threshold:\")\n",
        "    print(classification_report(y_test, y_pred_optimal,\n",
        "                                target_names=['Non-Planet', 'Planet'],\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "    \n",
        "    print(\"\\nPrediction distribution (optimal threshold):\")\n",
        "    print(f\"  Predicted 0: {(y_pred_optimal == 0).sum()}\")\n",
        "    print(f\"  Predicted 1: {(y_pred_optimal == 1).sum()}\")\n",
        "    print(\"True distribution:\")\n",
        "    print(f\"  True 0: {(y_test == 0).sum()}\")\n",
        "    print(f\"  True 1: {(y_test == 1).sum()}\")\n",
        "    \n",
        "    return y_pred_optimal, y_pred_proba, optimal_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1529af",
      "metadata": {},
      "source": [
        "## 9. Visualization (Matplotlib-only)\n",
        "\n",
        "We save:\n",
        "- **Confusion matrix** (`confusion_matrix_final.png`) with counts and percentages.  \n",
        "- **Training curves** (`training_history_final.png`).  \n",
        "- **Sample light curves with predictions** (`sample_lightcurves_predictions.png`).\n",
        "\n",
        "> We use **Matplotlib** exclusively to minimize dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7ce2d06d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, y_pred_proba, \n",
        "                                       metadata_test, scaler, threshold, n_samples=6,\n",
        "                                       save_path='sample_lightcurves_predictions.png'):\n",
        "    \"\"\"Plot light curves with error bars and prediction info; save to file.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PLOTTING LIGHTCURVES WITH PREDICTIONS (n={n_samples})\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    n_samples = min(n_samples, len(X_test_orig))\n",
        "    \n",
        "    # Select diverse samples: correct/incorrect for both classes\n",
        "    correct_planet = np.where((y_test == 1) & (y_pred == 1))[0]\n",
        "    incorrect_planet = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "    correct_nonplanet = np.where((y_test == 0) & (y_pred == 0))[0]\n",
        "    incorrect_nonplanet = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "    \n",
        "    selected_idx = []\n",
        "    per_category = max(1, n_samples // 4)\n",
        "    \n",
        "    for idx_list in [correct_planet, incorrect_planet, correct_nonplanet, incorrect_nonplanet]:\n",
        "        if len(idx_list) > 0:\n",
        "            n_select = min(per_category, len(idx_list))\n",
        "            selected_idx.extend(np.random.choice(idx_list, n_select, replace=False))\n",
        "    \n",
        "    while len(selected_idx) < n_samples:\n",
        "        remaining = list(set(range(len(y_test))) - set(selected_idx))\n",
        "        if remaining:\n",
        "            selected_idx.append(np.random.choice(remaining))\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    selected_idx = np.array(selected_idx[:n_samples])\n",
        "    \n",
        "    # Figure layout\n",
        "    n_cols = 2\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_samples == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for plot_i, idx in enumerate(selected_idx):\n",
        "        ax = axes[plot_i]\n",
        "        \n",
        "        # Inverse transform to original scale for plotting\n",
        "        flux_norm = X_test_orig[idx].flatten()\n",
        "        flux_err = X_err_test[idx]\n",
        "        flux_original = scaler.inverse_transform(flux_norm.reshape(1, -1)).flatten()\n",
        "        \n",
        "        time_bins = np.arange(len(flux_original))\n",
        "        \n",
        "        # Metadata\n",
        "        toi_name = metadata_test.loc[idx, 'toi_name']\n",
        "        tic = metadata_test.loc[idx, 'tic']\n",
        "        disp = metadata_test.loc[idx, 'disp']\n",
        "        sector = metadata_test.loc[idx, 'sector']\n",
        "        \n",
        "        true_label = y_test[idx]\n",
        "        pred_label = y_pred[idx]\n",
        "        pred_prob = y_pred_proba[idx]\n",
        "        \n",
        "        is_correct = (true_label == pred_label)\n",
        "        true_str = 'Transit' if true_label == 1 else 'Non-Transit'\n",
        "        pred_str = 'Transit' if pred_label == 1 else 'Non-Transit'\n",
        "        \n",
        "        # Errorbar plot\n",
        "        ax.errorbar(time_bins, flux_original, yerr=flux_err, fmt='o', markersize=2,\n",
        "                    ecolor='gray', elinewidth=0.5, capsize=0, alpha=0.6, label='Data')\n",
        "        \n",
        "        # Baseline median\n",
        "        baseline = np.median(flux_original)\n",
        "        ax.axhline(baseline, linestyle='--', linewidth=1, alpha=0.7, label='Baseline')\n",
        "        \n",
        "        ax.set_xlabel('Time Bin', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Flux (original scale)', fontsize=10, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "        \n",
        "        status_symbol = '✓' if is_correct else '✗'\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        title = (f'TOI {toi_name} (TIC {tic}, {disp}) - TESS Sector {sector}\\n'\n",
        "                 f'True: {true_str} | Pred: {pred_str} (p={pred_prob:.3f}) {status_symbol}')\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold', color=color, pad=10)\n",
        "        \n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(2.0)\n",
        "    \n",
        "    # Hide unused axes\n",
        "    for j in range(n_samples, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Sample Light-curve Predictions (Threshold={threshold:.3f})',\n",
        "                 fontsize=14, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=None, X_err_test=None, scaler=None):\n",
        "    \"\"\"Create and save confusion matrix and training curves. Optionally plot light curves.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Confusion matrix (Matplotlib-only)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(2),\n",
        "           yticks=np.arange(2),\n",
        "           xticklabels=['Non-Planet', 'Planet'],\n",
        "           yticklabels=['Non-Planet', 'Planet'],\n",
        "           xlabel='Predicted', ylabel='True',\n",
        "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
        "    \n",
        "    # Add counts and percentages\n",
        "    total = cm.sum()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            pct = (count / total * 100) if total > 0 else 0.0\n",
        "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center', color='black', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_final.png', dpi=300)\n",
        "    print(\"Saved: confusion_matrix_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Training history\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'),\n",
        "               ('auc', 'AUC'), ('recall', 'Recall')]\n",
        "    \n",
        "    for idx, (metric, title) in enumerate(metrics):\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        if metric in history.history and f'val_{metric}' in history.history:\n",
        "            ax.plot(history.history[metric], label='Train', linewidth=2)\n",
        "            ax.plot(history.history[f'val_{metric}'], label='Val', linewidth=2)\n",
        "            ax.set_xlabel('Epoch')\n",
        "            ax.set_ylabel(title)\n",
        "            ax.set_title(f'{title} vs Epoch', fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Training History - Final Model', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history_final.png', dpi=300)\n",
        "    print(\"Saved: training_history_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Optional: light-curve panel\n",
        "    if X_test_orig is not None and X_err_test is not None and scaler is not None:\n",
        "        plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, \n",
        "                                          y_pred_proba, metadata_test, scaler, threshold, n_samples=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b561a755",
      "metadata": {},
      "source": [
        "## 10. Run the Pipeline\n",
        "\n",
        "You can run the following cells **step by step**, or use the **end-to-end** cell.\n",
        "\n",
        "> If your CSV isn’t called `tess_data.csv`, change `CSV_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "053ea574",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to your dataset\n",
        "CSV_PATH = 'tess_data.csv'   # <- change me if needed\n",
        "N_BINS = 1000                # number of flux bins/columns per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bdfd93e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "Dataset: 944 samples\n",
            "\n",
            "Original distribution:\n",
            "  Class 0: 472, Class 1: 472\n",
            "  Ratio: 1.00:1\n",
            "\n",
            "Initial split - Train: 755, Test: 189\n",
            "\n",
            "======================================================================\n",
            "CREATING BALANCED DATASET\n",
            "======================================================================\n",
            "Original - Class 0: 377, Class 1: 378\n",
            "Balanced - Class 0: 350, Class 1: 350\n",
            "\n",
            "======================================================================\n",
            "STANDARDIZATION\n",
            "======================================================================\n",
            "Train: mean=-0.000000, std=1.000000\n",
            "Test:  mean=-0.001916, std=0.463545\n",
            "\n",
            "Final - X_train: (700, 1000, 1), X_test: (189, 1000, 1)\n",
            "Train dist: 0=350, 1=350\n"
          ]
        }
      ],
      "source": [
        "# 1) Load and prepare data\n",
        "X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "    csv_path=CSV_PATH, n_bins=N_BINS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e5abe27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n"
          ]
        }
      ],
      "source": [
        "# 2) Build model\n",
        "model = build_simple_cnn(n_bins=N_BINS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9d20cabc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4906 - auc: 0.4592 - loss: 0.8736 - precision: 0.4728 - recall: 0.7782\n",
            "Epoch 1: val_auc improved from None to 0.54782, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.5200 - auc: 0.5039 - loss: 0.8374 - precision: 0.5113 - recall: 0.9029 - val_accuracy: 0.5185 - val_auc: 0.5478 - val_loss: 0.7630 - val_precision: 0.5081 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4981 - auc: 0.4898 - loss: 0.7374 - precision: 0.4883 - recall: 0.9743\n",
            "Epoch 2: val_auc did not improve from 0.54782\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5257 - auc: 0.5230 - loss: 0.7096 - precision: 0.5136 - recall: 0.9743 - val_accuracy: 0.5026 - val_auc: 0.5263 - val_loss: 0.6493 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4822 - auc: 0.4867 - loss: 0.6350 - precision: 0.4795 - recall: 0.9508\n",
            "Epoch 3: val_auc improved from 0.54782 to 0.74698, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.5157 - auc: 0.5511 - loss: 0.6091 - precision: 0.5082 - recall: 0.9771 - val_accuracy: 0.5026 - val_auc: 0.7470 - val_loss: 0.5575 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5108 - auc: 0.5856 - loss: 0.5383 - precision: 0.4951 - recall: 0.9836\n",
            "Epoch 4: val_auc did not improve from 0.74698\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5329 - auc: 0.6154 - loss: 0.5189 - precision: 0.5175 - recall: 0.9743 - val_accuracy: 0.5026 - val_auc: 0.7058 - val_loss: 0.4818 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5235 - auc: 0.6232 - loss: 0.4626 - precision: 0.5022 - recall: 0.9814\n",
            "Epoch 5: val_auc did not improve from 0.74698\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.5500 - auc: 0.6528 - loss: 0.4458 - precision: 0.5271 - recall: 0.9714 - val_accuracy: 0.4974 - val_auc: 0.6894 - val_loss: 0.4153 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5251 - auc: 0.6846 - loss: 0.3983 - precision: 0.5033 - recall: 0.9776\n",
            "Epoch 6: val_auc did not improve from 0.74698\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5571 - auc: 0.6760 - loss: 0.3849 - precision: 0.5313 - recall: 0.9686 - val_accuracy: 0.4974 - val_auc: 0.6570 - val_loss: 0.3595 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5252 - auc: 0.6856 - loss: 0.3447 - precision: 0.5028 - recall: 0.9759\n",
            "Epoch 7: val_auc did not improve from 0.74698\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5500 - auc: 0.7122 - loss: 0.3326 - precision: 0.5270 - recall: 0.9771 - val_accuracy: 0.4974 - val_auc: 0.7017 - val_loss: 0.3137 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5305 - auc: 0.7398 - loss: 0.2985 - precision: 0.5058 - recall: 0.9953\n",
            "Epoch 8: val_auc did not improve from 0.74698\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5629 - auc: 0.7353 - loss: 0.2892 - precision: 0.5341 - recall: 0.9857 - val_accuracy: 0.4974 - val_auc: 0.7265 - val_loss: 0.2737 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5406 - auc: 0.7596 - loss: 0.2609 - precision: 0.5116 - recall: 0.9845\n",
            "Epoch 9: val_auc improved from 0.74698 to 0.79412, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5686 - auc: 0.7380 - loss: 0.2532 - precision: 0.5379 - recall: 0.9743 - val_accuracy: 0.4974 - val_auc: 0.7941 - val_loss: 0.2416 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5388 - auc: 0.7652 - loss: 0.2298 - precision: 0.5111 - recall: 0.9711\n",
            "Epoch 10: val_auc improved from 0.79412 to 0.79961, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5700 - auc: 0.7389 - loss: 0.2235 - precision: 0.5396 - recall: 0.9543 - val_accuracy: 0.5291 - val_auc: 0.7996 - val_loss: 0.2128 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5485 - auc: 0.7690 - loss: 0.2031 - precision: 0.5162 - recall: 0.9777\n",
            "Epoch 11: val_auc improved from 0.79961 to 0.82839, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5814 - auc: 0.7571 - loss: 0.1974 - precision: 0.5456 - recall: 0.9743 - val_accuracy: 0.5291 - val_auc: 0.8284 - val_loss: 0.1915 - val_precision: 0.5137 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5506 - auc: 0.7980 - loss: 0.1793 - precision: 0.5174 - recall: 0.9807\n",
            "Epoch 12: val_auc did not improve from 0.82839\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5843 - auc: 0.7724 - loss: 0.1751 - precision: 0.5474 - recall: 0.9743 - val_accuracy: 0.5608 - val_auc: 0.7664 - val_loss: 0.1882 - val_precision: 0.8667 - val_recall: 0.1383 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5697 - auc: 0.7861 - loss: 0.1613 - precision: 0.5305 - recall: 0.9616\n",
            "Epoch 13: val_auc improved from 0.82839 to 0.83511, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.6086 - auc: 0.7674 - loss: 0.1576 - precision: 0.5648 - recall: 0.9457 - val_accuracy: 0.5979 - val_auc: 0.8351 - val_loss: 0.1688 - val_precision: 0.9091 - val_recall: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5728 - auc: 0.7930 - loss: 0.1448 - precision: 0.5317 - recall: 0.9735\n",
            "Epoch 14: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.6143 - auc: 0.7757 - loss: 0.1415 - precision: 0.5676 - recall: 0.9600 - val_accuracy: 0.5503 - val_auc: 0.7838 - val_loss: 0.1683 - val_precision: 0.9091 - val_recall: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5814 - auc: 0.7946 - loss: 0.1317 - precision: 0.5370 - recall: 0.9686\n",
            "Epoch 15: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6086 - auc: 0.7721 - loss: 0.1293 - precision: 0.5651 - recall: 0.9429 - val_accuracy: 0.5926 - val_auc: 0.8275 - val_loss: 0.1490 - val_precision: 0.9474 - val_recall: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5829 - auc: 0.8116 - loss: 0.1189 - precision: 0.5375 - recall: 0.9781\n",
            "Epoch 16: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6229 - auc: 0.7947 - loss: 0.1167 - precision: 0.5734 - recall: 0.9600 - val_accuracy: 0.5503 - val_auc: 0.7872 - val_loss: 0.1598 - val_precision: 0.9091 - val_recall: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5947 - auc: 0.8231 - loss: 0.1086 - precision: 0.5465 - recall: 0.9588\n",
            "Epoch 17: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6357 - auc: 0.7987 - loss: 0.1069 - precision: 0.5841 - recall: 0.9429 - val_accuracy: 0.5503 - val_auc: 0.7937 - val_loss: 0.1508 - val_precision: 0.9091 - val_recall: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6167 - auc: 0.8056 - loss: 0.1013 - precision: 0.5636 - recall: 0.9360\n",
            "Epoch 18: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6443 - auc: 0.7757 - loss: 0.1002 - precision: 0.5937 - recall: 0.9143 - val_accuracy: 0.5979 - val_auc: 0.8174 - val_loss: 0.1036 - val_precision: 0.5584 - val_recall: 0.9149 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5780 - auc: 0.7931 - loss: 0.0954 - precision: 0.5344 - recall: 0.9745\n",
            "Epoch 19: val_auc did not improve from 0.83511\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6229 - auc: 0.7813 - loss: 0.0931 - precision: 0.5726 - recall: 0.9686 - val_accuracy: 0.5926 - val_auc: 0.8232 - val_loss: 0.1216 - val_precision: 0.9474 - val_recall: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5861 - auc: 0.8289 - loss: 0.0865 - precision: 0.5403 - recall: 0.9751\n",
            "Epoch 20: val_auc improved from 0.83511 to 0.83701, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.6443 - auc: 0.8031 - loss: 0.0860 - precision: 0.5875 - recall: 0.9686 - val_accuracy: 0.6032 - val_auc: 0.8370 - val_loss: 0.1165 - val_precision: 0.9524 - val_recall: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6224 - auc: 0.8271 - loss: 0.0810 - precision: 0.5664 - recall: 0.9378\n",
            "Epoch 21: val_auc did not improve from 0.83701\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.6457 - auc: 0.8010 - loss: 0.0809 - precision: 0.5941 - recall: 0.9200 - val_accuracy: 0.6138 - val_auc: 0.8181 - val_loss: 0.0870 - val_precision: 0.5724 - val_recall: 0.8830 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5957 - auc: 0.8075 - loss: 0.0782 - precision: 0.5463 - recall: 0.9623\n",
            "Epoch 22: val_auc did not improve from 0.83701\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6329 - auc: 0.7911 - loss: 0.0767 - precision: 0.5817 - recall: 0.9457 - val_accuracy: 0.6508 - val_auc: 0.8320 - val_loss: 0.0811 - val_precision: 0.6029 - val_recall: 0.8723 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6046 - auc: 0.8278 - loss: 0.0723 - precision: 0.5522 - recall: 0.9653\n",
            "Epoch 23: val_auc did not improve from 0.83701\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6514 - auc: 0.8101 - loss: 0.0718 - precision: 0.5950 - recall: 0.9486 - val_accuracy: 0.5926 - val_auc: 0.8358 - val_loss: 0.0737 - val_precision: 0.5541 - val_recall: 0.9255 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6298 - auc: 0.8212 - loss: 0.0695 - precision: 0.5727 - recall: 0.9317\n",
            "Epoch 24: val_auc did not improve from 0.83701\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.6614 - auc: 0.7956 - loss: 0.0694 - precision: 0.6068 - recall: 0.9171 - val_accuracy: 0.5767 - val_auc: 0.7619 - val_loss: 0.0758 - val_precision: 0.5412 - val_recall: 0.9787 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6058 - auc: 0.8150 - loss: 0.0666 - precision: 0.5535 - recall: 0.9623\n",
            "Epoch 25: val_auc improved from 0.83701 to 0.85347, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6557 - auc: 0.8055 - loss: 0.0658 - precision: 0.5982 - recall: 0.9486 - val_accuracy: 0.6296 - val_auc: 0.8535 - val_loss: 0.0673 - val_precision: 0.5789 - val_recall: 0.9362 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6322 - auc: 0.8399 - loss: 0.0619 - precision: 0.5706 - recall: 0.9655\n",
            "Epoch 26: val_auc did not improve from 0.85347\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.6657 - auc: 0.8149 - loss: 0.0623 - precision: 0.6066 - recall: 0.9429 - val_accuracy: 0.6984 - val_auc: 0.8391 - val_loss: 0.0701 - val_precision: 0.6480 - val_recall: 0.8617 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6485 - auc: 0.8342 - loss: 0.0603 - precision: 0.5864 - recall: 0.9415\n",
            "Epoch 27: val_auc did not improve from 0.85347\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6729 - auc: 0.8103 - loss: 0.0606 - precision: 0.6166 - recall: 0.9143 - val_accuracy: 0.5820 - val_auc: 0.8229 - val_loss: 0.0624 - val_precision: 0.5460 - val_recall: 0.9468 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6062 - auc: 0.8159 - loss: 0.0598 - precision: 0.5538 - recall: 0.9646\n",
            "Epoch 28: val_auc improved from 0.85347 to 0.85588, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6614 - auc: 0.8043 - loss: 0.0587 - precision: 0.6018 - recall: 0.9543 - val_accuracy: 0.5873 - val_auc: 0.8559 - val_loss: 0.0584 - val_precision: 0.5482 - val_recall: 0.9681 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6090 - auc: 0.8400 - loss: 0.0560 - precision: 0.5566 - recall: 0.9593\n",
            "Epoch 29: val_auc did not improve from 0.85588\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6586 - auc: 0.8196 - loss: 0.0559 - precision: 0.6030 - recall: 0.9286 - val_accuracy: 0.5979 - val_auc: 0.8466 - val_loss: 0.0579 - val_precision: 0.5570 - val_recall: 0.9362 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6562 - auc: 0.8388 - loss: 0.0540 - precision: 0.5912 - recall: 0.9397\n",
            "Epoch 30: val_auc did not improve from 0.85588\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6814 - auc: 0.8173 - loss: 0.0543 - precision: 0.6219 - recall: 0.9257 - val_accuracy: 0.5979 - val_auc: 0.8546 - val_loss: 0.0564 - val_precision: 0.5562 - val_recall: 0.9468 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6423 - auc: 0.8354 - loss: 0.0538 - precision: 0.5812 - recall: 0.9511\n",
            "Epoch 31: val_auc did not improve from 0.85588\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6786 - auc: 0.8120 - loss: 0.0538 - precision: 0.6190 - recall: 0.9286 - val_accuracy: 0.5820 - val_auc: 0.8195 - val_loss: 0.0656 - val_precision: 0.5439 - val_recall: 0.9894 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6143 - auc: 0.8282 - loss: 0.0534 - precision: 0.5605 - recall: 0.9514\n",
            "Epoch 32: val_auc improved from 0.85588 to 0.86142, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.6657 - auc: 0.8143 - loss: 0.0527 - precision: 0.6082 - recall: 0.9314 - val_accuracy: 0.5767 - val_auc: 0.8614 - val_loss: 0.0545 - val_precision: 0.5412 - val_recall: 0.9787 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6378 - auc: 0.8552 - loss: 0.0499 - precision: 0.5755 - recall: 0.9616\n",
            "Epoch 33: val_auc improved from 0.86142 to 0.86837, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.6829 - auc: 0.8392 - loss: 0.0497 - precision: 0.6199 - recall: 0.9457 - val_accuracy: 0.7989 - val_auc: 0.8684 - val_loss: 0.0545 - val_precision: 0.7642 - val_recall: 0.8617 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6979 - auc: 0.8580 - loss: 0.0482 - precision: 0.6267 - recall: 0.9347\n",
            "Epoch 34: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7014 - auc: 0.8336 - loss: 0.0492 - precision: 0.6419 - recall: 0.9114 - val_accuracy: 0.6667 - val_auc: 0.8577 - val_loss: 0.0737 - val_precision: 0.8974 - val_recall: 0.3723 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6878 - auc: 0.8548 - loss: 0.0478 - precision: 0.6167 - recall: 0.9415\n",
            "Epoch 35: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7071 - auc: 0.8354 - loss: 0.0482 - precision: 0.6465 - recall: 0.9143 - val_accuracy: 0.8413 - val_auc: 0.8536 - val_loss: 0.0561 - val_precision: 0.8556 - val_recall: 0.8191 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6428 - auc: 0.8537 - loss: 0.0479 - precision: 0.5795 - recall: 0.9533\n",
            "Epoch 36: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6871 - auc: 0.8312 - loss: 0.0478 - precision: 0.6262 - recall: 0.9286 - val_accuracy: 0.7407 - val_auc: 0.8644 - val_loss: 0.0624 - val_precision: 0.8814 - val_recall: 0.5532 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6607 - auc: 0.8731 - loss: 0.0452 - precision: 0.5918 - recall: 0.9592\n",
            "Epoch 37: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7000 - auc: 0.8476 - loss: 0.0458 - precision: 0.6357 - recall: 0.9371 - val_accuracy: 0.8254 - val_auc: 0.8568 - val_loss: 0.0526 - val_precision: 0.8081 - val_recall: 0.8511 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6998 - auc: 0.8622 - loss: 0.0449 - precision: 0.6243 - recall: 0.9495\n",
            "Epoch 38: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7157 - auc: 0.8478 - loss: 0.0455 - precision: 0.6513 - recall: 0.9286 - val_accuracy: 0.5873 - val_auc: 0.8330 - val_loss: 0.1005 - val_precision: 0.9000 - val_recall: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6828 - auc: 0.8709 - loss: 0.0445 - precision: 0.6126 - recall: 0.9396\n",
            "Epoch 39: val_auc did not improve from 0.86837\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7071 - auc: 0.8420 - loss: 0.0455 - precision: 0.6447 - recall: 0.9229 - val_accuracy: 0.6931 - val_auc: 0.8631 - val_loss: 0.0643 - val_precision: 0.8600 - val_recall: 0.4574 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6500 - auc: 0.8579 - loss: 0.0458 - precision: 0.5870 - recall: 0.9509\n",
            "Epoch 40: val_auc improved from 0.86837 to 0.88208, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7057 - auc: 0.8422 - loss: 0.0451 - precision: 0.6434 - recall: 0.9229 - val_accuracy: 0.6561 - val_auc: 0.8821 - val_loss: 0.0762 - val_precision: 0.9143 - val_recall: 0.3404 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6795 - auc: 0.8664 - loss: 0.0434 - precision: 0.6082 - recall: 0.9516\n",
            "Epoch 41: val_auc did not improve from 0.88208\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7143 - auc: 0.8514 - loss: 0.0438 - precision: 0.6512 - recall: 0.9229 - val_accuracy: 0.5873 - val_auc: 0.8508 - val_loss: 0.1059 - val_precision: 0.9000 - val_recall: 0.1915 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7176 - auc: 0.8687 - loss: 0.0424 - precision: 0.6383 - recall: 0.9569\n",
            "Epoch 42: val_auc did not improve from 0.88208\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.7314 - auc: 0.8574 - loss: 0.0424 - precision: 0.6653 - recall: 0.9314 - val_accuracy: 0.6138 - val_auc: 0.8532 - val_loss: 0.0820 - val_precision: 0.9200 - val_recall: 0.2447 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7031 - auc: 0.8587 - loss: 0.0430 - precision: 0.6283 - recall: 0.9491\n",
            "Epoch 43: val_auc did not improve from 0.88208\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7286 - auc: 0.8480 - loss: 0.0431 - precision: 0.6633 - recall: 0.9286 - val_accuracy: 0.7884 - val_auc: 0.8786 - val_loss: 0.0551 - val_precision: 0.8857 - val_recall: 0.6596 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7180 - auc: 0.8579 - loss: 0.0429 - precision: 0.6397 - recall: 0.9511\n",
            "Epoch 44: val_auc did not improve from 0.88208\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7414 - auc: 0.8494 - loss: 0.0426 - precision: 0.6749 - recall: 0.9314 - val_accuracy: 0.5820 - val_auc: 0.8775 - val_loss: 0.0448 - val_precision: 0.5444 - val_recall: 0.9787 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7032 - auc: 0.8629 - loss: 0.0420 - precision: 0.6258 - recall: 0.9620\n",
            "Epoch 45: val_auc did not improve from 0.88208\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7314 - auc: 0.8547 - loss: 0.0420 - precision: 0.6646 - recall: 0.9343 - val_accuracy: 0.6825 - val_auc: 0.8737 - val_loss: 0.0625 - val_precision: 0.8542 - val_recall: 0.4362 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7096 - auc: 0.8754 - loss: 0.0411 - precision: 0.6344 - recall: 0.9442\n",
            "Epoch 46: val_auc improved from 0.88208 to 0.88460, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7357 - auc: 0.8544 - loss: 0.0420 - precision: 0.6722 - recall: 0.9200 - val_accuracy: 0.5926 - val_auc: 0.8846 - val_loss: 0.0444 - val_precision: 0.5515 - val_recall: 0.9681 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6894 - auc: 0.8887 - loss: 0.0400 - precision: 0.6182 - recall: 0.9442\n",
            "Epoch 47: val_auc did not improve from 0.88460\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7400 - auc: 0.8707 - loss: 0.0402 - precision: 0.6765 - recall: 0.9200 - val_accuracy: 0.5926 - val_auc: 0.8560 - val_loss: 0.1026 - val_precision: 0.9048 - val_recall: 0.2021 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6976 - auc: 0.8787 - loss: 0.0403 - precision: 0.6212 - recall: 0.9633\n",
            "Epoch 48: val_auc improved from 0.88460 to 0.89300, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7414 - auc: 0.8620 - loss: 0.0408 - precision: 0.6721 - recall: 0.9429 - val_accuracy: 0.7619 - val_auc: 0.8930 - val_loss: 0.0561 - val_precision: 0.8889 - val_recall: 0.5957 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7040 - auc: 0.8725 - loss: 0.0402 - precision: 0.6295 - recall: 0.9428\n",
            "Epoch 49: val_auc improved from 0.89300 to 0.89653, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7414 - auc: 0.8666 - loss: 0.0401 - precision: 0.6757 - recall: 0.9286 - val_accuracy: 0.8836 - val_auc: 0.8965 - val_loss: 0.0444 - val_precision: 0.8673 - val_recall: 0.9043 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7069 - auc: 0.8756 - loss: 0.0405 - precision: 0.6312 - recall: 0.9562\n",
            "Epoch 50: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7443 - auc: 0.8608 - loss: 0.0407 - precision: 0.6770 - recall: 0.9343 - val_accuracy: 0.5503 - val_auc: 0.8470 - val_loss: 0.1497 - val_precision: 0.8462 - val_recall: 0.1170 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7323 - auc: 0.8807 - loss: 0.0397 - precision: 0.6544 - recall: 0.9441\n",
            "Epoch 51: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7586 - auc: 0.8623 - loss: 0.0404 - precision: 0.6930 - recall: 0.9286 - val_accuracy: 0.8783 - val_auc: 0.8958 - val_loss: 0.0462 - val_precision: 0.8817 - val_recall: 0.8723 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6796 - auc: 0.8697 - loss: 0.0409 - precision: 0.6101 - recall: 0.9414\n",
            "Epoch 52: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7286 - auc: 0.8569 - loss: 0.0406 - precision: 0.6633 - recall: 0.9286 - val_accuracy: 0.5979 - val_auc: 0.8639 - val_loss: 0.0923 - val_precision: 0.9091 - val_recall: 0.2128 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7034 - auc: 0.8711 - loss: 0.0406 - precision: 0.6273 - recall: 0.9567\n",
            "Epoch 53: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.7486 - auc: 0.8604 - loss: 0.0402 - precision: 0.6805 - recall: 0.9371 - val_accuracy: 0.7302 - val_auc: 0.8863 - val_loss: 0.0573 - val_precision: 0.8644 - val_recall: 0.5426 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7335 - auc: 0.8897 - loss: 0.0391 - precision: 0.6513 - recall: 0.9637\n",
            "Epoch 54: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7514 - auc: 0.8723 - loss: 0.0395 - precision: 0.6826 - recall: 0.9400 - val_accuracy: 0.5450 - val_auc: 0.8116 - val_loss: 0.1318 - val_precision: 0.7857 - val_recall: 0.1170 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7245 - auc: 0.8935 - loss: 0.0377 - precision: 0.6464 - recall: 0.9447\n",
            "Epoch 55: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7586 - auc: 0.8863 - loss: 0.0378 - precision: 0.6897 - recall: 0.9400 - val_accuracy: 0.5608 - val_auc: 0.8532 - val_loss: 0.1498 - val_precision: 0.8667 - val_recall: 0.1383 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7680 - auc: 0.8718 - loss: 0.0388 - precision: 0.6873 - recall: 0.9534\n",
            "Epoch 56: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7757 - auc: 0.8673 - loss: 0.0390 - precision: 0.7075 - recall: 0.9400 - val_accuracy: 0.6243 - val_auc: 0.8884 - val_loss: 0.0423 - val_precision: 0.5732 - val_recall: 0.9574 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7561 - auc: 0.8883 - loss: 0.0378 - precision: 0.6783 - recall: 0.9457\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 57: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7729 - auc: 0.8750 - loss: 0.0381 - precision: 0.7081 - recall: 0.9286 - val_accuracy: 0.6138 - val_auc: 0.8890 - val_loss: 0.0901 - val_precision: 0.9200 - val_recall: 0.2447 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7171 - auc: 0.8949 - loss: 0.0381 - precision: 0.6364 - recall: 0.9708\n",
            "Epoch 58: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7629 - auc: 0.8834 - loss: 0.0375 - precision: 0.6957 - recall: 0.9343 - val_accuracy: 0.5556 - val_auc: 0.8391 - val_loss: 0.1845 - val_precision: 0.8571 - val_recall: 0.1277 - learning_rate: 2.5000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7797 - auc: 0.9137 - loss: 0.0347 - precision: 0.6909 - recall: 0.9802\n",
            "Epoch 59: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7814 - auc: 0.9060 - loss: 0.0350 - precision: 0.7100 - recall: 0.9514 - val_accuracy: 0.5503 - val_auc: 0.8411 - val_loss: 0.2103 - val_precision: 0.8462 - val_recall: 0.1170 - learning_rate: 2.5000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7657 - auc: 0.9030 - loss: 0.0356 - precision: 0.6854 - recall: 0.9495\n",
            "Epoch 60: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7786 - auc: 0.8951 - loss: 0.0359 - precision: 0.7115 - recall: 0.9371 - val_accuracy: 0.5556 - val_auc: 0.8466 - val_loss: 0.1774 - val_precision: 0.8571 - val_recall: 0.1277 - learning_rate: 2.5000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7429 - auc: 0.9093 - loss: 0.0361 - precision: 0.6566 - recall: 0.9789\n",
            "Epoch 61: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7729 - auc: 0.8933 - loss: 0.0362 - precision: 0.7019 - recall: 0.9486 - val_accuracy: 0.5344 - val_auc: 0.8314 - val_loss: 0.2457 - val_precision: 0.7500 - val_recall: 0.0957 - learning_rate: 2.5000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7908 - auc: 0.9109 - loss: 0.0342 - precision: 0.7036 - recall: 0.9752\n",
            "Epoch 62: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8043 - auc: 0.9061 - loss: 0.0345 - precision: 0.7310 - recall: 0.9629 - val_accuracy: 0.5450 - val_auc: 0.8324 - val_loss: 0.2883 - val_precision: 0.9000 - val_recall: 0.0957 - learning_rate: 2.5000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7908 - auc: 0.9137 - loss: 0.0335 - precision: 0.7105 - recall: 0.9544\n",
            "Epoch 63: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7871 - auc: 0.9039 - loss: 0.0348 - precision: 0.7209 - recall: 0.9371 - val_accuracy: 0.5714 - val_auc: 0.8578 - val_loss: 0.1602 - val_precision: 0.8421 - val_recall: 0.1702 - learning_rate: 2.5000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7799 - auc: 0.9211 - loss: 0.0337 - precision: 0.6935 - recall: 0.9719\n",
            "Epoch 64: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8029 - auc: 0.9095 - loss: 0.0339 - precision: 0.7314 - recall: 0.9571 - val_accuracy: 0.5556 - val_auc: 0.8400 - val_loss: 0.2000 - val_precision: 0.8125 - val_recall: 0.1383 - learning_rate: 2.5000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7785 - auc: 0.9172 - loss: 0.0340 - precision: 0.6929 - recall: 0.9686\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 65: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8014 - auc: 0.9058 - loss: 0.0344 - precision: 0.7309 - recall: 0.9543 - val_accuracy: 0.5132 - val_auc: 0.7844 - val_loss: 0.4027 - val_precision: 0.6250 - val_recall: 0.0532 - learning_rate: 2.5000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7941 - auc: 0.9126 - loss: 0.0339 - precision: 0.7139 - recall: 0.9548\n",
            "Epoch 66: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7886 - auc: 0.9108 - loss: 0.0339 - precision: 0.7177 - recall: 0.9514 - val_accuracy: 0.5397 - val_auc: 0.8186 - val_loss: 0.3020 - val_precision: 1.0000 - val_recall: 0.0745 - learning_rate: 1.2500e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7833 - auc: 0.9110 - loss: 0.0343 - precision: 0.6974 - recall: 0.9709\n",
            "Epoch 67: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8014 - auc: 0.9068 - loss: 0.0342 - precision: 0.7319 - recall: 0.9514 - val_accuracy: 0.5397 - val_auc: 0.8081 - val_loss: 0.3120 - val_precision: 1.0000 - val_recall: 0.0745 - learning_rate: 1.2500e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7867 - auc: 0.9212 - loss: 0.0327 - precision: 0.6977 - recall: 0.9809\n",
            "Epoch 68: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.7929 - auc: 0.9146 - loss: 0.0332 - precision: 0.7214 - recall: 0.9543 - val_accuracy: 0.5079 - val_auc: 0.7981 - val_loss: 0.3381 - val_precision: 0.5556 - val_recall: 0.0532 - learning_rate: 1.2500e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7974 - auc: 0.9094 - loss: 0.0342 - precision: 0.7153 - recall: 0.9614\n",
            "Epoch 69: val_auc did not improve from 0.89653\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8029 - auc: 0.9105 - loss: 0.0338 - precision: 0.7356 - recall: 0.9457 - val_accuracy: 0.5397 - val_auc: 0.8085 - val_loss: 0.3040 - val_precision: 0.8182 - val_recall: 0.0957 - learning_rate: 1.2500e-04\n",
            "Epoch 69: early stopping\n",
            "Restoring model weights from the end of the best epoch: 49.\n"
          ]
        }
      ],
      "source": [
        "# 3) Train\n",
        "history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b0baecc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.5014 (default=0.5)\n",
            "  At this threshold: TPR=0.9043, FPR=0.1263\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8994\n",
            "  Accuracy (default threshold=0.5): 0.8836 (88.36%)\n",
            "  Accuracy (optimal threshold=0.5014): 0.8889 (88.89%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.9022    0.8737    0.8877        95\n",
            "      Planet     0.8763    0.9043    0.8901        94\n",
            "\n",
            "    accuracy                         0.8889       189\n",
            "   macro avg     0.8892    0.8890    0.8889       189\n",
            "weighted avg     0.8893    0.8889    0.8889       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 92\n",
            "  Predicted 1: 97\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n"
          ]
        }
      ],
      "source": [
        "# 4) Evaluate with optimal threshold\n",
        "y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a6e0f6da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Key improvements:\n",
            "  ✓ Perfectly balanced training data\n",
            "  ✓ Focal loss for hard examples\n",
            "  ✓ Optimal threshold selection\n",
            "  ✓ AUC-focused optimization\n",
            "\n",
            "Files:\n",
            "  - tess_model_final.keras\n",
            "  - best_model_final.keras\n",
            "  - optimal_threshold.npy\n",
            "  - confusion_matrix_final.png\n",
            "  - training_history_final.png\n",
            "  - sample_lightcurves_predictions.png\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Visualize & save artifacts\n",
        "plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "         X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "\n",
        "# Persist model and threshold\n",
        "model.save('tess_model_final.keras')\n",
        "np.save('optimal_threshold.npy', threshold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ✓ Perfectly balanced training data\")\n",
        "print(\"  ✓ Focal loss for hard examples\")\n",
        "print(\"  ✓ Optimal threshold selection\")\n",
        "print(\"  ✓ AUC-focused optimization\")\n",
        "print(\"\\nFiles:\")\n",
        "print(\"  - tess_model_final.keras\")\n",
        "print(\"  - best_model_final.keras\")\n",
        "print(\"  - optimal_threshold.npy\")\n",
        "print(\"  - confusion_matrix_final.png\")\n",
        "print(\"  - training_history_final.png\")\n",
        "print(\"  - sample_lightcurves_predictions.png\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e9d45",
      "metadata": {},
      "source": [
        "## 11. (Optional) One-Click: Run Everything\n",
        "\n",
        "This cell wraps all steps into a single function for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "42f938a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "        csv_path=CSV_PATH, n_bins=N_BINS\n",
        "    )\n",
        "    model = build_simple_cnn(n_bins=N_BINS)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)\n",
        "    y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)\n",
        "    plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "    model.save('tess_model_final.keras')\n",
        "    np.save('optimal_threshold.npy', threshold)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nKey improvements:\")\n",
        "    print(\"  ✓ Perfectly balanced training data\")\n",
        "    print(\"  ✓ Focal loss for hard examples\")\n",
        "    print(\"  ✓ Optimal threshold selection\")\n",
        "    print(\"  ✓ AUC-focused optimization\")\n",
        "    print(\"\\nFiles:\")\n",
        "    print(\"  - tess_model_final.keras\")\n",
        "    print(\"  - best_model_final.keras\")\n",
        "    print(\"  - optimal_threshold.npy\")\n",
        "    print(\"  - confusion_matrix_final.png\")\n",
        "    print(\"  - training_history_final.png\")\n",
        "    print(\"  - sample_lightcurves_predictions.png\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Uncomment to run end-to-end:\n",
        "# main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interpreting Results & Next Steps\n",
        "\n",
        "- **AUC-ROC** is the primary score during training. Inspect training curves to ensure you’re not overfitting.  \n",
        "- **Confusion matrix** with counts and percentages helps quantify trade-offs at the **optimal threshold**.  \n",
        "- **False positives** vs **false negatives**: use domain needs to decide how to tune `alpha`/`gamma` in focal loss or to move the threshold.\n",
        "\n",
        "**Ideas to try next**\n",
        "\n",
        "- Add **class-dependent augmentations** (e.g., transit-like dips for positives).  \n",
        "- Calibrate probabilities (e.g., **Platt scaling**, **isotonic regression**) for better decision thresholds.  \n",
        "- Incorporate additional channels (centroid motion, background, etc.) into a **multi-input** model.  \n",
        "- Use **cross-validation** on the training set to measure variability across folds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Appendix: Notes on Data Schema\n",
        "\n",
        "- Ensure your CSV contains **exactly** `n_bins` columns named `flux_0000 .. flux_{n_bins-1:04d}` and matching `flux_err_*` columns.\n",
        "- Metadata columns are optional for training but used for prettier plots.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- `ValueError: columns not found`: your CSV headers don’t match the expected names. Check `n_bins` and column prefixes.  \n",
        "- `CUDA out of memory`: reduce `batch_size`, or limit GPU memory; try the provided GPU memory-growth snippet.  \n",
        "- `AUC not improving`: try a bigger `samples_per_class`, more dropout, or adjust `gamma`/`alpha`.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_TESS_Transit_Classification.ipynb"
    },
    "kernelspec": {
      "display_name": "assignment1_taskE",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
