{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final TESS Transit Classification — Optimized for Extreme Class Imbalance\n",
        "\n",
        "This notebook converts and expands the provided Python script into a fully documented, didactic, and **step-by-step** workflow.\n",
        "We train a 1D CNN to classify TESS light curves into *transit* (planet candidate) vs *non-transit* under **severe class imbalance**.\n",
        "\n",
        "**Key strategies covered:**\n",
        "\n",
        "- **Balanced augmentation** (equal samples per class) to mitigate imbalance during training.  \n",
        "- **Focal loss** (tunable `gamma` and `alpha`) to emphasize hard examples and rare positives.  \n",
        "- **Threshold optimization** using **Youden’s J** from the ROC curve (don’t use the default 0.5).  \n",
        "- **Simplified CNN architecture** to reduce overfitting.  \n",
        "- **AUC-centric monitoring** with early stopping and LR scheduling.\n",
        "\n",
        "> **What you’ll learn**\n",
        ">\n",
        "> 1. Why balanced training batches help under extreme imbalance.  \n",
        "> 2. How focal loss reshapes the gradient to focus on hard/rare samples.  \n",
        "> 3. How to pick a **data-driven** decision threshold that best trades off TPR/FPR.  \n",
        "> 4. How to evaluate with AUC-ROC rather than accuracy (which can be misleading).  \n",
        "> 5. How to visualize confusion matrices and sample light curves with predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Prerequisites & Data\n",
        "\n",
        "**Dependencies** (install if needed):\n",
        "\n",
        "```bash\n",
        "pip install numpy pandas scikit-learn matplotlib tensorflow\n",
        "```\n",
        "\n",
        "> We intentionally avoid additional plotting libraries to keep dependencies compact.  \n",
        "> If you already have a working scientific Python/TensorFlow stack, you can skip installations.\n",
        "\n",
        "**Expected dataset**: a CSV file named **`tess_data.csv`** in the working directory with:\n",
        "\n",
        "- **Light-curve samples**: `flux_0000, flux_0001, ..., flux_0999` (or up to `n_bins-1`)  \n",
        "- **Flux uncertainties**: `flux_err_0000, ..., flux_err_0999`  \n",
        "- **Label**: `label` (0 = Non-Planet, 1 = Planet)  \n",
        "- **Metadata** (used for plots/titles): `toi_name, tic, disp, period_d, t0_bjd, dur_hr, sector`\n",
        "\n",
        "You can change the filename or number of bins via parameters in the **Data Loading** section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment Setup\n",
        "\n",
        "Set up imports, suppress noisy warnings, and fix seeds for reproducibility.  \n",
        "(Exact reproducibility on GPUs may still vary across hardware/driver versions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "883a4745",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting working directory to:  /Users/tiziano/Dropbox/Computational Astrophysics/25_26/Kepler and TESS Classification/final\n",
            "None\n",
            "======================================================================\n",
            "FINAL TESS CLASSIFICATION\n",
            "======================================================================\n",
            "TF version: 2.17.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import IPython\n",
        "    working_directory = \"/\".join(\n",
        "            IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"].split(\"/\")[:-1]\n",
        "        )\n",
        "    print(\"Setting working directory to: \", working_directory)\n",
        "    print(os.chdir(working_directory))\n",
        "except Exception as e:\n",
        "    print(\"It was impossible to set your directory as the current one because of the following message\")\n",
        "    print(e)\n",
        "    print(\"The working directory is: \", os.getcwd())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FINAL TESS CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Optional: make TF less eager to pre-allocate all GPU memory (if using GPU)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    if gpus:\n",
        "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
        "except Exception as e:\n",
        "    print(\"GPU setup note:\", e)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201e4a1",
      "metadata": {},
      "source": [
        "## 3. Focal Loss (for severe imbalance)\n",
        "\n",
        "**Why focal loss?** With extreme imbalance, the model can get “lazy”—it learns to do well by focusing on the majority class.  \n",
        "Focal loss down-weights *easy* examples and concentrates gradient on *hard* ones by adding a modulating factor \\((1 - p_t)^\\gamma\\).  \n",
        "We also use class weighting via \\(\\alpha\\) to up-weight the rare positive class.\n",
        "\n",
        "- **`gamma`** (focusing parameter): higher values put more emphasis on hard examples.  \n",
        "- **`alpha`** (class weight): weight for positive class (1); negative class gets \\(1 - \\alpha\\).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a2de8e26",
      "metadata": {},
      "outputs": [],
      "source": [
        "def focal_loss(gamma=2.5, alpha=0.75):\n",
        "    \"\"\"Focal loss optimized for severe imbalance (binary).\"\"\"\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        \n",
        "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        alpha_factor = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
        "        focal_weight = alpha_factor * K.pow(1 - pt, gamma)\n",
        "        bce = -K.log(pt)\n",
        "        return K.mean(focal_weight * bce)\n",
        "    return focal_loss_fixed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ae786d",
      "metadata": {},
      "source": [
        "## 4. Balanced Augmentation\n",
        "\n",
        "We **balance the training set** to a fixed number of samples per class.  \n",
        "If a class has too few samples, we create augmented variants (noise, scale, shift, combo).  \n",
        "This prevents the model from being swamped by the majority class during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "24800de1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_balanced_dataset(X, y, samples_per_class=400):\n",
        "    \"\"\"Create a perfectly balanced dataset via lightweight augmentations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING BALANCED DATASET\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    X_class0 = X[y == 0]\n",
        "    X_class1 = X[y == 1]\n",
        "    \n",
        "    print(f\"Original - Class 0: {len(X_class0)}, Class 1: {len(X_class1)}\")\n",
        "    \n",
        "    def augment_to_target(X_orig, n_target):\n",
        "        if len(X_orig) >= n_target:\n",
        "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
        "            return X_orig[idx]\n",
        "        \n",
        "        X_result = [X_orig]\n",
        "        while len(np.vstack(X_result)) < n_target:\n",
        "            # number we still need (cap to avoid oversampling too big chunks)\n",
        "            n_needed = n_target - len(np.vstack(X_result))\n",
        "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
        "            \n",
        "            aug_type = np.random.rand()\n",
        "            if aug_type < 0.25:\n",
        "                # Additive Gaussian noise\n",
        "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
        "            elif aug_type < 0.5:\n",
        "                # Multiplicative scaling\n",
        "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
        "                X_aug = X_orig[idx] * scale\n",
        "            elif aug_type < 0.75:\n",
        "                # Circular shift (time shift)\n",
        "                shifts = np.random.randint(-20, 20, len(idx))\n",
        "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
        "            else:\n",
        "                # Mild combo: small scale + small noise\n",
        "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
        "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
        "            \n",
        "            X_result.append(X_aug)\n",
        "        \n",
        "        X_final = np.vstack(X_result)\n",
        "        return X_final[:n_target]\n",
        "    \n",
        "    X0_bal = augment_to_target(X_class0, samples_per_class)\n",
        "    X1_bal = augment_to_target(X_class1, samples_per_class)\n",
        "    \n",
        "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
        "    \n",
        "    X_balanced = np.vstack([X0_bal, X1_bal])\n",
        "    y_balanced = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
        "    \n",
        "    # Shuffle\n",
        "    idx = np.arange(len(X_balanced))\n",
        "    np.random.shuffle(idx)\n",
        "    \n",
        "    return X_balanced[idx], y_balanced[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34555fb8",
      "metadata": {},
      "source": [
        "## 5. Data Loading, Splitting & Standardization\n",
        "\n",
        "We split **before** augmentation (to avoid leakage), then **balance only the training split**.  \n",
        "We standardize the flux (zero mean / unit variance) using statistics from the training set only.\n",
        "\n",
        "**Notes**\n",
        "\n",
        "- Error bars `X_err` are **not** standardized (kept in their original scale).  \n",
        "- We keep the **test metadata** to produce nicer titles in the sample light-curve plots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45df1a84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(csv_path='tess_data.csv', n_bins=1000):\n",
        "    \"\"\"Load CSV, split, balance train set, and standardize features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATA\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Dataset: {df.shape[0]} samples\")\n",
        "    \n",
        "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
        "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
        "    X = df[flux_cols].values\n",
        "    X_err = df[flux_err_cols].values\n",
        "    y = df['label'].values\n",
        "    \n",
        "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
        "    metadata = df[metadata_cols]\n",
        "    \n",
        "    print(\"\\nOriginal distribution:\")\n",
        "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
        "    if (y==0).sum() > 0:\n",
        "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
        "    \n",
        "    # Train/test split (keep errors aligned; stratify to preserve class ratio)\n",
        "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
        "        X, y, X_err, np.arange(len(y)),\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=y\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nInitial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    \n",
        "    # Balance training set\n",
        "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=350)\n",
        "    \n",
        "    # Standardize (fit on train, apply to test)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STANDARDIZATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
        "    print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
        "    \n",
        "    # Reshape for Conv1D: (samples, timesteps, channels)\n",
        "    X_train = X_train.reshape(-1, n_bins, 1)\n",
        "    X_test = X_test.reshape(-1, n_bins, 1)\n",
        "    \n",
        "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\nFinal - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "    print(f\"Train dist: 0={( y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
        "    \n",
        "    # Return standardized test for model input, but also return the standardized\n",
        "    # copy (X_test_orig) so we can inverse-transform for plotting with error bars.\n",
        "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e4e6b5",
      "metadata": {},
      "source": [
        "## 6. A Simpler 1D CNN (to curb overfitting)\n",
        "\n",
        "A compact ConvNet with **BatchNorm**, **Dropout**, and **Global Average Pooling** is often enough for\n",
        "noisy, small-ish 1D signals. We also add mild L2 on the dense layers. The goal is a strong baseline\n",
        "that generalizes well, not a gigantic model that memorizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c42e5a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_simple_cnn(n_bins=1000):\n",
        "    \"\"\"Simpler CNN to prevent overfitting on small datasets.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING SIMPLIFIED CNN\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(n_bins, 1)),\n",
        "        \n",
        "        # Feature extraction\n",
        "        layers.Conv1D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Dropout(0.3),\n",
        "        \n",
        "        layers.Conv1D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dropout(0.4),\n",
        "        \n",
        "        # Classification head\n",
        "        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        \n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=focal_loss(gamma=2.5, alpha=0.75),\n",
        "        metrics=['accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    \n",
        "    model.summary()\n",
        "    print(\"\\nUsing Focal Loss (gamma=2.5, alpha=0.75)\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28417447",
      "metadata": {},
      "source": [
        "## 7. Training with AUC Monitoring, Early Stopping & LR Scheduling\n",
        "\n",
        "We monitor **validation AUC** (not accuracy) and:\n",
        "\n",
        "- **EarlyStopping** on `val_auc` with patience to stop when progress stalls.  \n",
        "- **ReduceLROnPlateau** to gently lower the LR when AUC plateaus.  \n",
        "- **ModelCheckpoint** to persist the best model by AUC.\n",
        "\n",
        "> Tip: If your dataset is *very* small, increase dropout and/or reduce dense layers further.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "799553e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
        "    \"\"\"Train the model with AUC-centric callbacks.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_auc',\n",
        "            patience=20,\n",
        "            restore_best_weights=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_auc',\n",
        "            factor=0.5,\n",
        "            patience=8,\n",
        "            min_lr=1e-7,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model_final.keras',\n",
        "            monitor='val_auc',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fd997b",
      "metadata": {},
      "source": [
        "## 8. Evaluation with **Optimal Threshold** (don’t default to 0.5)\n",
        "\n",
        "The default threshold (0.5) is rarely optimal with imbalanced data.  \n",
        "We compute ROC, then choose the threshold that maximizes **Youden’s J** (\\(\\mathrm{TPR} - \\mathrm{FPR}\\)).\n",
        "We report both the default and the optimal settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b85e7698",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
        "    \"\"\"Find an optimal threshold from ROC (Youden's J) and evaluate.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    \n",
        "    # Youden's J statistic\n",
        "    j_scores = tpr - fpr\n",
        "    optimal_idx = np.argmax(j_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "    \n",
        "    print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (default=0.5)\")\n",
        "    print(f\"  At this threshold: TPR={tpr[optimal_idx]:.4f}, FPR={fpr[optimal_idx]:.4f}\")\n",
        "    \n",
        "    # Predictions with optimal vs default thresholds\n",
        "    y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "    y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
        "    \n",
        "    # Metrics\n",
        "    acc_optimal = accuracy_score(y_test, y_pred_optimal)\n",
        "    acc_default = accuracy_score(y_test, y_pred_default)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    \n",
        "    print(\"\\nResults:\")\n",
        "    print(f\"  AUC-ROC: {auc:.4f}\")\n",
        "    print(f\"  Accuracy (default threshold=0.5): {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
        "    print(f\"  Accuracy (optimal threshold={optimal_threshold:.4f}): {acc_optimal:.4f} ({acc_optimal*100:.2f}%)\")\n",
        "    \n",
        "    print(\"\\nWith optimal threshold:\")\n",
        "    print(classification_report(y_test, y_pred_optimal,\n",
        "                                target_names=['Non-Planet', 'Planet'],\n",
        "                                digits=4,\n",
        "                                zero_division=0))\n",
        "    \n",
        "    print(\"\\nPrediction distribution (optimal threshold):\")\n",
        "    print(f\"  Predicted 0: {(y_pred_optimal == 0).sum()}\")\n",
        "    print(f\"  Predicted 1: {(y_pred_optimal == 1).sum()}\")\n",
        "    print(\"True distribution:\")\n",
        "    print(f\"  True 0: {(y_test == 0).sum()}\")\n",
        "    print(f\"  True 1: {(y_test == 1).sum()}\")\n",
        "    \n",
        "    return y_pred_optimal, y_pred_proba, optimal_threshold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e1529af",
      "metadata": {},
      "source": [
        "## 9. Visualization (Matplotlib-only)\n",
        "\n",
        "We save:\n",
        "- **Confusion matrix** (`confusion_matrix_final.png`) with counts and percentages.  \n",
        "- **Training curves** (`training_history_final.png`).  \n",
        "- **Sample light curves with predictions** (`sample_lightcurves_predictions.png`).\n",
        "\n",
        "> We use **Matplotlib** exclusively to minimize dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7ce2d06d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, y_pred_proba, \n",
        "                                       metadata_test, scaler, threshold, n_samples=6,\n",
        "                                       save_path='sample_lightcurves_predictions.png'):\n",
        "    \"\"\"Plot light curves with error bars and prediction info; save to file.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"PLOTTING LIGHTCURVES WITH PREDICTIONS (n={n_samples})\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    n_samples = min(n_samples, len(X_test_orig))\n",
        "    \n",
        "    # Select diverse samples: correct/incorrect for both classes\n",
        "    correct_planet = np.where((y_test == 1) & (y_pred == 1))[0]\n",
        "    incorrect_planet = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "    correct_nonplanet = np.where((y_test == 0) & (y_pred == 0))[0]\n",
        "    incorrect_nonplanet = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "    \n",
        "    selected_idx = []\n",
        "    per_category = max(1, n_samples // 4)\n",
        "    \n",
        "    for idx_list in [correct_planet, incorrect_planet, correct_nonplanet, incorrect_nonplanet]:\n",
        "        if len(idx_list) > 0:\n",
        "            n_select = min(per_category, len(idx_list))\n",
        "            selected_idx.extend(np.random.choice(idx_list, n_select, replace=False))\n",
        "    \n",
        "    while len(selected_idx) < n_samples:\n",
        "        remaining = list(set(range(len(y_test))) - set(selected_idx))\n",
        "        if remaining:\n",
        "            selected_idx.append(np.random.choice(remaining))\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    selected_idx = np.array(selected_idx[:n_samples])\n",
        "    \n",
        "    # Figure layout\n",
        "    n_cols = 2\n",
        "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
        "    if n_samples == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for plot_i, idx in enumerate(selected_idx):\n",
        "        ax = axes[plot_i]\n",
        "        \n",
        "        # Inverse transform to original scale for plotting\n",
        "        flux_norm = X_test_orig[idx].flatten()\n",
        "        flux_err = X_err_test[idx]\n",
        "        flux_original = scaler.inverse_transform(flux_norm.reshape(1, -1)).flatten()\n",
        "        \n",
        "        time_bins = np.arange(len(flux_original))\n",
        "        \n",
        "        # Metadata\n",
        "        toi_name = metadata_test.loc[idx, 'toi_name']\n",
        "        tic = metadata_test.loc[idx, 'tic']\n",
        "        disp = metadata_test.loc[idx, 'disp']\n",
        "        sector = metadata_test.loc[idx, 'sector']\n",
        "        \n",
        "        true_label = y_test[idx]\n",
        "        pred_label = y_pred[idx]\n",
        "        pred_prob = y_pred_proba[idx]\n",
        "        \n",
        "        is_correct = (true_label == pred_label)\n",
        "        true_str = 'Transit' if true_label == 1 else 'Non-Transit'\n",
        "        pred_str = 'Transit' if pred_label == 1 else 'Non-Transit'\n",
        "        \n",
        "        # Errorbar plot\n",
        "        ax.errorbar(time_bins, flux_original, yerr=flux_err, fmt='o', markersize=2,\n",
        "                    ecolor='gray', elinewidth=0.5, capsize=0, alpha=0.6, label='Data')\n",
        "        \n",
        "        # Baseline median\n",
        "        baseline = np.median(flux_original)\n",
        "        ax.axhline(baseline, linestyle='--', linewidth=1, alpha=0.7, label='Baseline')\n",
        "        \n",
        "        ax.set_xlabel('Time Bin', fontsize=10, fontweight='bold')\n",
        "        ax.set_ylabel('Flux (original scale)', fontsize=10, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "        \n",
        "        status_symbol = '✓' if is_correct else '✗'\n",
        "        color = 'green' if is_correct else 'red'\n",
        "        title = (f'TOI {toi_name} (TIC {tic}, {disp}) - TESS Sector {sector}\\n'\n",
        "                 f'True: {true_str} | Pred: {pred_str} (p={pred_prob:.3f}) {status_symbol}')\n",
        "        ax.set_title(title, fontsize=10, fontweight='bold', color=color, pad=10)\n",
        "        \n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(2.0)\n",
        "    \n",
        "    # Hide unused axes\n",
        "    for j in range(n_samples, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Sample Light-curve Predictions (Threshold={threshold:.3f})',\n",
        "                 fontsize=14, fontweight='bold', y=0.995)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=None, X_err_test=None, scaler=None):\n",
        "    \"\"\"Create and save confusion matrix and training curves. Optionally plot light curves.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Confusion matrix (Matplotlib-only)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(2),\n",
        "           yticks=np.arange(2),\n",
        "           xticklabels=['Non-Planet', 'Planet'],\n",
        "           yticklabels=['Non-Planet', 'Planet'],\n",
        "           xlabel='Predicted', ylabel='True',\n",
        "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
        "    \n",
        "    # Add counts and percentages\n",
        "    total = cm.sum()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            pct = (count / total * 100) if total > 0 else 0.0\n",
        "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center', color='black', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix_final.png', dpi=300)\n",
        "    print(\"Saved: confusion_matrix_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Training history\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    metrics = [('loss', 'Loss'), ('accuracy', 'Accuracy'),\n",
        "               ('auc', 'AUC'), ('recall', 'Recall')]\n",
        "    \n",
        "    for idx, (metric, title) in enumerate(metrics):\n",
        "        ax = axes[idx // 2, idx % 2]\n",
        "        if metric in history.history and f'val_{metric}' in history.history:\n",
        "            ax.plot(history.history[metric], label='Train', linewidth=2)\n",
        "            ax.plot(history.history[f'val_{metric}'], label='Val', linewidth=2)\n",
        "            ax.set_xlabel('Epoch')\n",
        "            ax.set_ylabel(title)\n",
        "            ax.set_title(f'{title} vs Epoch', fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(alpha=0.3)\n",
        "    \n",
        "    plt.suptitle('Training History - Final Model', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history_final.png', dpi=300)\n",
        "    print(\"Saved: training_history_final.png\")\n",
        "    plt.close()\n",
        "    \n",
        "    # Optional: light-curve panel\n",
        "    if X_test_orig is not None and X_err_test is not None and scaler is not None:\n",
        "        plot_lightcurves_with_predictions(X_test_orig, X_err_test, y_test, y_pred, \n",
        "                                          y_pred_proba, metadata_test, scaler, threshold, n_samples=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b561a755",
      "metadata": {},
      "source": [
        "## 10. Run the Pipeline\n",
        "\n",
        "You can run the following cells **step by step**, or use the **end-to-end** cell.\n",
        "\n",
        "> If your CSV isn’t called `tess_data.csv`, change `CSV_PATH` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "053ea574",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to your dataset\n",
        "CSV_PATH = 'tess_data.csv'   # <- change me if needed\n",
        "N_BINS = 1000                # number of flux bins/columns per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bdfd93e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING DATA\n",
            "======================================================================\n",
            "Dataset: 944 samples\n",
            "\n",
            "Original distribution:\n",
            "  Class 0: 472, Class 1: 472\n",
            "  Ratio: 1.00:1\n",
            "\n",
            "Initial split - Train: 755, Test: 189\n",
            "\n",
            "======================================================================\n",
            "CREATING BALANCED DATASET\n",
            "======================================================================\n",
            "Original - Class 0: 377, Class 1: 378\n",
            "Balanced - Class 0: 350, Class 1: 350\n",
            "\n",
            "======================================================================\n",
            "STANDARDIZATION\n",
            "======================================================================\n",
            "Train: mean=-0.000000, std=1.000000\n",
            "Test:  mean=-0.001916, std=0.463545\n",
            "\n",
            "Final - X_train: (700, 1000, 1), X_test: (189, 1000, 1)\n",
            "Train dist: 0=350, 1=350\n"
          ]
        }
      ],
      "source": [
        "# 1) Load and prepare data\n",
        "X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "    csv_path=CSV_PATH, n_bins=N_BINS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8e5abe27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BUILDING SIMPLIFIED CNN\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m98,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,249</span> (1.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m421,249\u001b[0m (1.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">420,353</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m420,353\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Using Focal Loss (gamma=2.5, alpha=0.75)\n"
          ]
        }
      ],
      "source": [
        "# 2) Build model\n",
        "model = build_simple_cnn(n_bins=N_BINS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d20cabc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING\n",
            "======================================================================\n",
            "Epoch 1/200\n",
            "\u001b[1m21/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5039 - auc: 0.4905 - loss: 0.8690 - precision: 0.4882 - recall: 0.8727\n",
            "Epoch 1: val_auc improved from -inf to 0.54787, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.5056 - auc: 0.4938 - loss: 0.8655 - precision: 0.4904 - recall: 0.8783 - val_accuracy: 0.4974 - val_auc: 0.5479 - val_loss: 0.7486 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4996 - auc: 0.5168 - loss: 0.7235 - precision: 0.4891 - recall: 0.9683\n",
            "Epoch 2: val_auc improved from 0.54787 to 0.61624, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5007 - auc: 0.5179 - loss: 0.7223 - precision: 0.4901 - recall: 0.9682 - val_accuracy: 0.4974 - val_auc: 0.6162 - val_loss: 0.6340 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.4952 - auc: 0.5480 - loss: 0.6128 - precision: 0.4871 - recall: 0.9754\n",
            "Epoch 3: val_auc improved from 0.61624 to 0.71601, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.4964 - auc: 0.5495 - loss: 0.6118 - precision: 0.4882 - recall: 0.9750 - val_accuracy: 0.5026 - val_auc: 0.7160 - val_loss: 0.5430 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5087 - auc: 0.6591 - loss: 0.5218 - precision: 0.4941 - recall: 0.9917\n",
            "Epoch 4: val_auc did not improve from 0.71601\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5099 - auc: 0.6597 - loss: 0.5210 - precision: 0.4952 - recall: 0.9914 - val_accuracy: 0.4974 - val_auc: 0.6882 - val_loss: 0.4669 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5222 - auc: 0.6931 - loss: 0.4472 - precision: 0.5013 - recall: 0.9872\n",
            "Epoch 5: val_auc did not improve from 0.71601\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5236 - auc: 0.6925 - loss: 0.4465 - precision: 0.5025 - recall: 0.9869 - val_accuracy: 0.5026 - val_auc: 0.6278 - val_loss: 0.4032 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5258 - auc: 0.6863 - loss: 0.3861 - precision: 0.5030 - recall: 0.9817\n",
            "Epoch 6: val_auc improved from 0.71601 to 0.74787, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5268 - auc: 0.6863 - loss: 0.3855 - precision: 0.5040 - recall: 0.9817 - val_accuracy: 0.5026 - val_auc: 0.7479 - val_loss: 0.3487 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5245 - auc: 0.7320 - loss: 0.3332 - precision: 0.5022 - recall: 0.9812\n",
            "Epoch 7: val_auc did not improve from 0.74787\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.5255 - auc: 0.7322 - loss: 0.3327 - precision: 0.5032 - recall: 0.9814 - val_accuracy: 0.5026 - val_auc: 0.7282 - val_loss: 0.3034 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5442 - auc: 0.7478 - loss: 0.2905 - precision: 0.5140 - recall: 0.9652\n",
            "Epoch 8: val_auc improved from 0.74787 to 0.79043, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.5456 - auc: 0.7470 - loss: 0.2901 - precision: 0.5153 - recall: 0.9651 - val_accuracy: 0.4974 - val_auc: 0.7904 - val_loss: 0.2663 - val_precision: 0.4974 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5365 - auc: 0.7703 - loss: 0.2537 - precision: 0.5090 - recall: 0.9840\n",
            "Epoch 9: val_auc improved from 0.79043 to 0.80577, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.5379 - auc: 0.7698 - loss: 0.2534 - precision: 0.5102 - recall: 0.9840 - val_accuracy: 0.5026 - val_auc: 0.8058 - val_loss: 0.2344 - val_precision: 0.5000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5601 - auc: 0.7534 - loss: 0.2241 - precision: 0.5235 - recall: 0.9648\n",
            "Epoch 10: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5615 - auc: 0.7528 - loss: 0.2239 - precision: 0.5247 - recall: 0.9647 - val_accuracy: 0.6720 - val_auc: 0.7636 - val_loss: 0.2171 - val_precision: 0.6212 - val_recall: 0.8723 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5429 - auc: 0.7803 - loss: 0.1982 - precision: 0.5125 - recall: 0.9861\n",
            "Epoch 11: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.5442 - auc: 0.7798 - loss: 0.1979 - precision: 0.5136 - recall: 0.9862 - val_accuracy: 0.6138 - val_auc: 0.7805 - val_loss: 0.1972 - val_precision: 0.8000 - val_recall: 0.2979 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5648 - auc: 0.7868 - loss: 0.1761 - precision: 0.5263 - recall: 0.9759\n",
            "Epoch 12: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5664 - auc: 0.7859 - loss: 0.1760 - precision: 0.5277 - recall: 0.9753 - val_accuracy: 0.5397 - val_auc: 0.7562 - val_loss: 0.1923 - val_precision: 0.7692 - val_recall: 0.1064 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5812 - auc: 0.8005 - loss: 0.1579 - precision: 0.5376 - recall: 0.9569\n",
            "Epoch 13: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.5828 - auc: 0.7988 - loss: 0.1578 - precision: 0.5391 - recall: 0.9561 - val_accuracy: 0.5185 - val_auc: 0.7289 - val_loss: 0.1858 - val_precision: 1.0000 - val_recall: 0.0319 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5720 - auc: 0.7651 - loss: 0.1443 - precision: 0.5303 - recall: 0.9764\n",
            "Epoch 14: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.5735 - auc: 0.7652 - loss: 0.1442 - precision: 0.5316 - recall: 0.9762 - val_accuracy: 0.5132 - val_auc: 0.7466 - val_loss: 0.1905 - val_precision: 0.7500 - val_recall: 0.0319 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5814 - auc: 0.8241 - loss: 0.1287 - precision: 0.5364 - recall: 0.9764\n",
            "Epoch 15: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5831 - auc: 0.8229 - loss: 0.1286 - precision: 0.5379 - recall: 0.9759 - val_accuracy: 0.5079 - val_auc: 0.7414 - val_loss: 0.2159 - val_precision: 1.0000 - val_recall: 0.0106 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6088 - auc: 0.7921 - loss: 0.1189 - precision: 0.5550 - recall: 0.9639\n",
            "Epoch 16: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.6103 - auc: 0.7917 - loss: 0.1188 - precision: 0.5564 - recall: 0.9631 - val_accuracy: 0.5185 - val_auc: 0.7438 - val_loss: 0.1849 - val_precision: 1.0000 - val_recall: 0.0319 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5651 - auc: 0.8114 - loss: 0.1095 - precision: 0.5264 - recall: 0.9774\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 17: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.5671 - auc: 0.8103 - loss: 0.1094 - precision: 0.5281 - recall: 0.9770 - val_accuracy: 0.5132 - val_auc: 0.7405 - val_loss: 0.2066 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5938 - auc: 0.8086 - loss: 0.1019 - precision: 0.5449 - recall: 0.9712\n",
            "Epoch 18: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.5960 - auc: 0.8079 - loss: 0.1019 - precision: 0.5469 - recall: 0.9707 - val_accuracy: 0.5132 - val_auc: 0.7309 - val_loss: 0.2177 - val_precision: 1.0000 - val_recall: 0.0213 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6235 - auc: 0.8372 - loss: 0.0961 - precision: 0.5642 - recall: 0.9678\n",
            "Epoch 19: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6252 - auc: 0.8363 - loss: 0.0961 - precision: 0.5659 - recall: 0.9672 - val_accuracy: 0.5238 - val_auc: 0.7653 - val_loss: 0.2015 - val_precision: 1.0000 - val_recall: 0.0426 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6507 - auc: 0.8455 - loss: 0.0918 - precision: 0.5838 - recall: 0.9638\n",
            "Epoch 20: val_auc did not improve from 0.80577\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6520 - auc: 0.8445 - loss: 0.0918 - precision: 0.5853 - recall: 0.9631 - val_accuracy: 0.5450 - val_auc: 0.7847 - val_loss: 0.1839 - val_precision: 1.0000 - val_recall: 0.0851 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6267 - auc: 0.8355 - loss: 0.0896 - precision: 0.5673 - recall: 0.9591\n",
            "Epoch 21: val_auc improved from 0.80577 to 0.83096, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6283 - auc: 0.8347 - loss: 0.0896 - precision: 0.5690 - recall: 0.9584 - val_accuracy: 0.5979 - val_auc: 0.8310 - val_loss: 0.1232 - val_precision: 0.9500 - val_recall: 0.2021 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6347 - auc: 0.8272 - loss: 0.0868 - precision: 0.5724 - recall: 0.9712\n",
            "Epoch 22: val_auc improved from 0.83096 to 0.83847, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6363 - auc: 0.8264 - loss: 0.0868 - precision: 0.5740 - recall: 0.9700 - val_accuracy: 0.6190 - val_auc: 0.8385 - val_loss: 0.1155 - val_precision: 0.9583 - val_recall: 0.2447 - learning_rate: 2.5000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6497 - auc: 0.8456 - loss: 0.0825 - precision: 0.5815 - recall: 0.9718\n",
            "Epoch 23: val_auc did not improve from 0.83847\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6511 - auc: 0.8446 - loss: 0.0825 - precision: 0.5831 - recall: 0.9713 - val_accuracy: 0.6243 - val_auc: 0.8340 - val_loss: 0.1126 - val_precision: 0.9259 - val_recall: 0.2660 - learning_rate: 2.5000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6516 - auc: 0.8409 - loss: 0.0803 - precision: 0.5851 - recall: 0.9620\n",
            "Epoch 24: val_auc did not improve from 0.83847\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6529 - auc: 0.8398 - loss: 0.0803 - precision: 0.5866 - recall: 0.9611 - val_accuracy: 0.6138 - val_auc: 0.8226 - val_loss: 0.0892 - val_precision: 0.5724 - val_recall: 0.8830 - learning_rate: 2.5000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6307 - auc: 0.8397 - loss: 0.0783 - precision: 0.5703 - recall: 0.9623\n",
            "Epoch 25: val_auc did not improve from 0.83847\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.6323 - auc: 0.8389 - loss: 0.0782 - precision: 0.5720 - recall: 0.9616 - val_accuracy: 0.5926 - val_auc: 0.8361 - val_loss: 0.0808 - val_precision: 0.5515 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6269 - auc: 0.8490 - loss: 0.0755 - precision: 0.5677 - recall: 0.9659\n",
            "Epoch 26: val_auc did not improve from 0.83847\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6289 - auc: 0.8477 - loss: 0.0755 - precision: 0.5696 - recall: 0.9650 - val_accuracy: 0.5767 - val_auc: 0.8157 - val_loss: 0.0858 - val_precision: 0.5412 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6285 - auc: 0.8272 - loss: 0.0742 - precision: 0.5686 - recall: 0.9644\n",
            "Epoch 27: val_auc improved from 0.83847 to 0.84177, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6302 - auc: 0.8267 - loss: 0.0742 - precision: 0.5703 - recall: 0.9635 - val_accuracy: 0.6032 - val_auc: 0.8418 - val_loss: 0.0761 - val_precision: 0.5590 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6463 - auc: 0.8433 - loss: 0.0711 - precision: 0.5806 - recall: 0.9633\n",
            "Epoch 28: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6476 - auc: 0.8424 - loss: 0.0711 - precision: 0.5820 - recall: 0.9624 - val_accuracy: 0.5873 - val_auc: 0.8243 - val_loss: 0.0757 - val_precision: 0.5482 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6410 - auc: 0.8471 - loss: 0.0693 - precision: 0.5772 - recall: 0.9608\n",
            "Epoch 29: val_auc did not improve from 0.84177\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6423 - auc: 0.8461 - loss: 0.0693 - precision: 0.5787 - recall: 0.9598 - val_accuracy: 0.5926 - val_auc: 0.8133 - val_loss: 0.0739 - val_precision: 0.5528 - val_recall: 0.9468 - learning_rate: 2.5000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6340 - auc: 0.8443 - loss: 0.0678 - precision: 0.5733 - recall: 0.9578\n",
            "Epoch 30: val_auc improved from 0.84177 to 0.84323, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6360 - auc: 0.8436 - loss: 0.0678 - precision: 0.5753 - recall: 0.9571 - val_accuracy: 0.5979 - val_auc: 0.8432 - val_loss: 0.0700 - val_precision: 0.5556 - val_recall: 0.9574 - learning_rate: 2.5000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6457 - auc: 0.8453 - loss: 0.0651 - precision: 0.5801 - recall: 0.9741\n",
            "Epoch 31: val_auc did not improve from 0.84323\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6473 - auc: 0.8448 - loss: 0.0651 - precision: 0.5818 - recall: 0.9728 - val_accuracy: 0.5926 - val_auc: 0.8277 - val_loss: 0.0719 - val_precision: 0.5509 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6595 - auc: 0.8232 - loss: 0.0648 - precision: 0.5933 - recall: 0.9408\n",
            "Epoch 32: val_auc improved from 0.84323 to 0.84759, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6604 - auc: 0.8232 - loss: 0.0648 - precision: 0.5944 - recall: 0.9401 - val_accuracy: 0.5873 - val_auc: 0.8476 - val_loss: 0.0676 - val_precision: 0.5476 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6500 - auc: 0.8500 - loss: 0.0625 - precision: 0.5846 - recall: 0.9609\n",
            "Epoch 33: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6514 - auc: 0.8489 - loss: 0.0625 - precision: 0.5862 - recall: 0.9599 - val_accuracy: 0.5820 - val_auc: 0.8395 - val_loss: 0.0683 - val_precision: 0.5444 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6467 - auc: 0.8541 - loss: 0.0606 - precision: 0.5813 - recall: 0.9638\n",
            "Epoch 34: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.6480 - auc: 0.8531 - loss: 0.0607 - precision: 0.5828 - recall: 0.9631 - val_accuracy: 0.5873 - val_auc: 0.8357 - val_loss: 0.0667 - val_precision: 0.5476 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6638 - auc: 0.8439 - loss: 0.0597 - precision: 0.5930 - recall: 0.9692\n",
            "Epoch 35: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6651 - auc: 0.8433 - loss: 0.0597 - precision: 0.5945 - recall: 0.9680 - val_accuracy: 0.5979 - val_auc: 0.8322 - val_loss: 0.0646 - val_precision: 0.5542 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6464 - auc: 0.8578 - loss: 0.0585 - precision: 0.5833 - recall: 0.9499\n",
            "Epoch 36: val_auc did not improve from 0.84759\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6481 - auc: 0.8568 - loss: 0.0585 - precision: 0.5852 - recall: 0.9488 - val_accuracy: 0.5979 - val_auc: 0.8255 - val_loss: 0.0636 - val_precision: 0.5562 - val_recall: 0.9468 - learning_rate: 2.5000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6561 - auc: 0.8628 - loss: 0.0568 - precision: 0.5868 - recall: 0.9723\n",
            "Epoch 37: val_auc improved from 0.84759 to 0.85689, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.6574 - auc: 0.8620 - loss: 0.0568 - precision: 0.5882 - recall: 0.9717 - val_accuracy: 0.7778 - val_auc: 0.8569 - val_loss: 0.0663 - val_precision: 0.7407 - val_recall: 0.8511 - learning_rate: 2.5000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6689 - auc: 0.8485 - loss: 0.0564 - precision: 0.5996 - recall: 0.9540\n",
            "Epoch 38: val_auc did not improve from 0.85689\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6702 - auc: 0.8479 - loss: 0.0565 - precision: 0.6011 - recall: 0.9530 - val_accuracy: 0.6190 - val_auc: 0.8428 - val_loss: 0.0624 - val_precision: 0.5724 - val_recall: 0.9255 - learning_rate: 2.5000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6539 - auc: 0.8517 - loss: 0.0556 - precision: 0.5864 - recall: 0.9651\n",
            "Epoch 39: val_auc did not improve from 0.85689\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.6555 - auc: 0.8510 - loss: 0.0556 - precision: 0.5881 - recall: 0.9640 - val_accuracy: 0.6349 - val_auc: 0.8415 - val_loss: 0.0637 - val_precision: 0.5887 - val_recall: 0.8830 - learning_rate: 2.5000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6585 - auc: 0.8553 - loss: 0.0538 - precision: 0.5895 - recall: 0.9704\n",
            "Epoch 40: val_auc did not improve from 0.85689\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.6602 - auc: 0.8546 - loss: 0.0538 - precision: 0.5913 - recall: 0.9692 - val_accuracy: 0.7619 - val_auc: 0.8566 - val_loss: 0.0619 - val_precision: 0.7094 - val_recall: 0.8830 - learning_rate: 2.5000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6728 - auc: 0.8715 - loss: 0.0518 - precision: 0.6000 - recall: 0.9717\n",
            "Epoch 41: val_auc did not improve from 0.85689\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.6744 - auc: 0.8705 - loss: 0.0518 - precision: 0.6018 - recall: 0.9706 - val_accuracy: 0.5979 - val_auc: 0.8179 - val_loss: 0.0593 - val_precision: 0.5562 - val_recall: 0.9468 - learning_rate: 2.5000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6715 - auc: 0.8552 - loss: 0.0522 - precision: 0.5998 - recall: 0.9633\n",
            "Epoch 42: val_auc improved from 0.85689 to 0.86209, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6731 - auc: 0.8547 - loss: 0.0522 - precision: 0.6016 - recall: 0.9628 - val_accuracy: 0.6243 - val_auc: 0.8621 - val_loss: 0.0560 - val_precision: 0.5742 - val_recall: 0.9468 - learning_rate: 2.5000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6779 - auc: 0.8628 - loss: 0.0509 - precision: 0.6055 - recall: 0.9664\n",
            "Epoch 43: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6793 - auc: 0.8621 - loss: 0.0509 - precision: 0.6072 - recall: 0.9653 - val_accuracy: 0.5979 - val_auc: 0.8447 - val_loss: 0.0564 - val_precision: 0.5549 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6787 - auc: 0.8492 - loss: 0.0511 - precision: 0.6060 - recall: 0.9584\n",
            "Epoch 44: val_auc did not improve from 0.86209\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6802 - auc: 0.8486 - loss: 0.0511 - precision: 0.6077 - recall: 0.9577 - val_accuracy: 0.5926 - val_auc: 0.8323 - val_loss: 0.0569 - val_precision: 0.5509 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6737 - auc: 0.8681 - loss: 0.0494 - precision: 0.6026 - recall: 0.9555\n",
            "Epoch 45: val_auc improved from 0.86209 to 0.86428, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6752 - auc: 0.8671 - loss: 0.0494 - precision: 0.6044 - recall: 0.9545 - val_accuracy: 0.7884 - val_auc: 0.8643 - val_loss: 0.0644 - val_precision: 0.8649 - val_recall: 0.6809 - learning_rate: 2.5000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6870 - auc: 0.8596 - loss: 0.0491 - precision: 0.6131 - recall: 0.9582\n",
            "Epoch 46: val_auc did not improve from 0.86428\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6878 - auc: 0.8584 - loss: 0.0492 - precision: 0.6144 - recall: 0.9571 - val_accuracy: 0.5979 - val_auc: 0.8073 - val_loss: 0.0567 - val_precision: 0.5542 - val_recall: 0.9787 - learning_rate: 2.5000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6618 - auc: 0.8463 - loss: 0.0494 - precision: 0.5926 - recall: 0.9630\n",
            "Epoch 47: val_auc improved from 0.86428 to 0.86596, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.6635 - auc: 0.8460 - loss: 0.0494 - precision: 0.5945 - recall: 0.9623 - val_accuracy: 0.7989 - val_auc: 0.8660 - val_loss: 0.0620 - val_precision: 0.8684 - val_recall: 0.7021 - learning_rate: 2.5000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6673 - auc: 0.8627 - loss: 0.0478 - precision: 0.5969 - recall: 0.9667\n",
            "Epoch 48: val_auc improved from 0.86596 to 0.86786, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.6692 - auc: 0.8621 - loss: 0.0478 - precision: 0.5989 - recall: 0.9661 - val_accuracy: 0.7513 - val_auc: 0.8679 - val_loss: 0.0552 - val_precision: 0.6880 - val_recall: 0.9149 - learning_rate: 2.5000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6738 - auc: 0.8585 - loss: 0.0474 - precision: 0.6025 - recall: 0.9628\n",
            "Epoch 49: val_auc did not improve from 0.86786\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6756 - auc: 0.8581 - loss: 0.0474 - precision: 0.6044 - recall: 0.9620 - val_accuracy: 0.6402 - val_auc: 0.8427 - val_loss: 0.0567 - val_precision: 0.5929 - val_recall: 0.8830 - learning_rate: 2.5000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6565 - auc: 0.8613 - loss: 0.0474 - precision: 0.5908 - recall: 0.9640\n",
            "Epoch 50: val_auc improved from 0.86786 to 0.87996, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6589 - auc: 0.8603 - loss: 0.0474 - precision: 0.5931 - recall: 0.9630 - val_accuracy: 0.6931 - val_auc: 0.8800 - val_loss: 0.0720 - val_precision: 0.9091 - val_recall: 0.4255 - learning_rate: 2.5000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6576 - auc: 0.8704 - loss: 0.0465 - precision: 0.5891 - recall: 0.9710\n",
            "Epoch 51: val_auc did not improve from 0.87996\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.6590 - auc: 0.8693 - loss: 0.0465 - precision: 0.5907 - recall: 0.9701 - val_accuracy: 0.6825 - val_auc: 0.8710 - val_loss: 0.0745 - val_precision: 0.9048 - val_recall: 0.4043 - learning_rate: 2.5000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6654 - auc: 0.8651 - loss: 0.0461 - precision: 0.5969 - recall: 0.9656\n",
            "Epoch 52: val_auc improved from 0.87996 to 0.88186, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.6677 - auc: 0.8643 - loss: 0.0461 - precision: 0.5991 - recall: 0.9653 - val_accuracy: 0.7143 - val_auc: 0.8819 - val_loss: 0.0687 - val_precision: 0.9000 - val_recall: 0.4787 - learning_rate: 2.5000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6655 - auc: 0.8676 - loss: 0.0460 - precision: 0.5965 - recall: 0.9628\n",
            "Epoch 53: val_auc did not improve from 0.88186\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6678 - auc: 0.8668 - loss: 0.0460 - precision: 0.5989 - recall: 0.9618 - val_accuracy: 0.6720 - val_auc: 0.8753 - val_loss: 0.0799 - val_precision: 0.9000 - val_recall: 0.3830 - learning_rate: 2.5000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6795 - auc: 0.8574 - loss: 0.0454 - precision: 0.6059 - recall: 0.9637\n",
            "Epoch 54: val_auc improved from 0.88186 to 0.88763, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.6811 - auc: 0.8572 - loss: 0.0454 - precision: 0.6077 - recall: 0.9632 - val_accuracy: 0.6296 - val_auc: 0.8876 - val_loss: 0.0980 - val_precision: 0.9615 - val_recall: 0.2660 - learning_rate: 2.5000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7072 - auc: 0.8796 - loss: 0.0432 - precision: 0.6275 - recall: 0.9720\n",
            "Epoch 55: val_auc did not improve from 0.88763\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.7083 - auc: 0.8789 - loss: 0.0432 - precision: 0.6289 - recall: 0.9711 - val_accuracy: 0.6296 - val_auc: 0.8728 - val_loss: 0.0857 - val_precision: 0.9286 - val_recall: 0.2766 - learning_rate: 2.5000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7034 - auc: 0.8788 - loss: 0.0431 - precision: 0.6261 - recall: 0.9587\n",
            "Epoch 56: val_auc did not improve from 0.88763\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7044 - auc: 0.8779 - loss: 0.0431 - precision: 0.6275 - recall: 0.9578 - val_accuracy: 0.6032 - val_auc: 0.8759 - val_loss: 0.0935 - val_precision: 0.9524 - val_recall: 0.2128 - learning_rate: 2.5000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7026 - auc: 0.8652 - loss: 0.0441 - precision: 0.6259 - recall: 0.9589\n",
            "Epoch 57: val_auc improved from 0.88763 to 0.89524, saving model to best_model_final.keras\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.7035 - auc: 0.8646 - loss: 0.0441 - precision: 0.6272 - recall: 0.9582 - val_accuracy: 0.7884 - val_auc: 0.8952 - val_loss: 0.0567 - val_precision: 0.8750 - val_recall: 0.6702 - learning_rate: 2.5000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6711 - auc: 0.8644 - loss: 0.0445 - precision: 0.6035 - recall: 0.9490\n",
            "Epoch 58: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6732 - auc: 0.8637 - loss: 0.0445 - precision: 0.6057 - recall: 0.9481 - val_accuracy: 0.6032 - val_auc: 0.8314 - val_loss: 0.0496 - val_precision: 0.5583 - val_recall: 0.9681 - learning_rate: 2.5000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6908 - auc: 0.8644 - loss: 0.0434 - precision: 0.6146 - recall: 0.9695\n",
            "Epoch 59: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.6925 - auc: 0.8640 - loss: 0.0434 - precision: 0.6166 - recall: 0.9686 - val_accuracy: 0.7725 - val_auc: 0.8915 - val_loss: 0.0585 - val_precision: 0.8806 - val_recall: 0.6277 - learning_rate: 2.5000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7201 - auc: 0.8859 - loss: 0.0414 - precision: 0.6365 - recall: 0.9816\n",
            "Epoch 60: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7214 - auc: 0.8855 - loss: 0.0414 - precision: 0.6381 - recall: 0.9809 - val_accuracy: 0.6190 - val_auc: 0.8746 - val_loss: 0.0978 - val_precision: 0.8929 - val_recall: 0.2660 - learning_rate: 2.5000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7523 - auc: 0.8958 - loss: 0.0397 - precision: 0.6701 - recall: 0.9579\n",
            "Epoch 61: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7525 - auc: 0.8953 - loss: 0.0397 - precision: 0.6709 - recall: 0.9570 - val_accuracy: 0.5926 - val_auc: 0.8693 - val_loss: 0.1094 - val_precision: 0.9474 - val_recall: 0.1915 - learning_rate: 2.5000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7240 - auc: 0.8680 - loss: 0.0420 - precision: 0.6453 - recall: 0.9528\n",
            "Epoch 62: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7246 - auc: 0.8673 - loss: 0.0421 - precision: 0.6465 - recall: 0.9519 - val_accuracy: 0.5661 - val_auc: 0.8530 - val_loss: 0.1401 - val_precision: 1.0000 - val_recall: 0.1277 - learning_rate: 2.5000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7054 - auc: 0.8620 - loss: 0.0433 - precision: 0.6288 - recall: 0.9551\n",
            "Epoch 63: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.7067 - auc: 0.8617 - loss: 0.0433 - precision: 0.6304 - recall: 0.9546 - val_accuracy: 0.5979 - val_auc: 0.8905 - val_loss: 0.1057 - val_precision: 0.9500 - val_recall: 0.2021 - learning_rate: 2.5000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6808 - auc: 0.8732 - loss: 0.0425 - precision: 0.6050 - recall: 0.9841\n",
            "Epoch 64: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.6834 - auc: 0.8728 - loss: 0.0425 - precision: 0.6077 - recall: 0.9834 - val_accuracy: 0.5714 - val_auc: 0.8671 - val_loss: 0.1733 - val_precision: 0.9333 - val_recall: 0.1489 - learning_rate: 2.5000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7262 - auc: 0.8823 - loss: 0.0404 - precision: 0.6430 - recall: 0.9737\n",
            "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 65: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7277 - auc: 0.8819 - loss: 0.0403 - precision: 0.6448 - recall: 0.9733 - val_accuracy: 0.5556 - val_auc: 0.8547 - val_loss: 0.2059 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 2.5000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7350 - auc: 0.8866 - loss: 0.0395 - precision: 0.6509 - recall: 0.9737\n",
            "Epoch 66: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.7366 - auc: 0.8863 - loss: 0.0395 - precision: 0.6530 - recall: 0.9728 - val_accuracy: 0.5556 - val_auc: 0.8299 - val_loss: 0.2285 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7281 - auc: 0.8996 - loss: 0.0390 - precision: 0.6431 - recall: 0.9784\n",
            "Epoch 67: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.7296 - auc: 0.8990 - loss: 0.0390 - precision: 0.6450 - recall: 0.9777 - val_accuracy: 0.5503 - val_auc: 0.8275 - val_loss: 0.2797 - val_precision: 1.0000 - val_recall: 0.0957 - learning_rate: 1.2500e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7391 - auc: 0.8892 - loss: 0.0389 - precision: 0.6550 - recall: 0.9699\n",
            "Epoch 68: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.7401 - auc: 0.8889 - loss: 0.0389 - precision: 0.6565 - recall: 0.9691 - val_accuracy: 0.5556 - val_auc: 0.8534 - val_loss: 0.2127 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7250 - auc: 0.8903 - loss: 0.0393 - precision: 0.6417 - recall: 0.9743\n",
            "Epoch 69: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.7264 - auc: 0.8898 - loss: 0.0393 - precision: 0.6437 - recall: 0.9729 - val_accuracy: 0.5556 - val_auc: 0.8534 - val_loss: 0.2127 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7495 - auc: 0.9027 - loss: 0.0379 - precision: 0.6652 - recall: 0.9677\n",
            "Epoch 70: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7506 - auc: 0.9021 - loss: 0.0379 - precision: 0.6669 - recall: 0.9667 - val_accuracy: 0.5556 - val_auc: 0.8232 - val_loss: 0.2506 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7480 - auc: 0.9029 - loss: 0.0374 - precision: 0.6591 - recall: 0.9887\n",
            "Epoch 71: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7490 - auc: 0.9026 - loss: 0.0374 - precision: 0.6606 - recall: 0.9879 - val_accuracy: 0.5556 - val_auc: 0.8318 - val_loss: 0.2508 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 1.2500e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7311 - auc: 0.8929 - loss: 0.0383 - precision: 0.6472 - recall: 0.9735\n",
            "Epoch 72: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7324 - auc: 0.8924 - loss: 0.0383 - precision: 0.6490 - recall: 0.9726 - val_accuracy: 0.5608 - val_auc: 0.8373 - val_loss: 0.2270 - val_precision: 1.0000 - val_recall: 0.1170 - learning_rate: 1.2500e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7386 - auc: 0.8943 - loss: 0.0382 - precision: 0.6534 - recall: 0.9759\n",
            "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 73: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7397 - auc: 0.8938 - loss: 0.0382 - precision: 0.6550 - recall: 0.9751 - val_accuracy: 0.5714 - val_auc: 0.8740 - val_loss: 0.1519 - val_precision: 0.9333 - val_recall: 0.1489 - learning_rate: 1.2500e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7322 - auc: 0.8967 - loss: 0.0384 - precision: 0.6457 - recall: 0.9846\n",
            "Epoch 74: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.7339 - auc: 0.8964 - loss: 0.0383 - precision: 0.6478 - recall: 0.9839 - val_accuracy: 0.5556 - val_auc: 0.8377 - val_loss: 0.2355 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 6.2500e-05\n",
            "Epoch 75/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7736 - auc: 0.9072 - loss: 0.0360 - precision: 0.6855 - recall: 0.9768\n",
            "Epoch 75: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.7742 - auc: 0.9069 - loss: 0.0360 - precision: 0.6867 - recall: 0.9761 - val_accuracy: 0.5556 - val_auc: 0.8442 - val_loss: 0.2425 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 6.2500e-05\n",
            "Epoch 76/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7614 - auc: 0.8996 - loss: 0.0368 - precision: 0.6766 - recall: 0.9654\n",
            "Epoch 76: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7621 - auc: 0.8993 - loss: 0.0368 - precision: 0.6780 - recall: 0.9646 - val_accuracy: 0.5608 - val_auc: 0.8428 - val_loss: 0.2404 - val_precision: 1.0000 - val_recall: 0.1170 - learning_rate: 6.2500e-05\n",
            "Epoch 77/200\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7726 - auc: 0.9084 - loss: 0.0358 - precision: 0.6848 - recall: 0.9758\n",
            "Epoch 77: val_auc did not improve from 0.89524\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7729 - auc: 0.9079 - loss: 0.0358 - precision: 0.6859 - recall: 0.9750 - val_accuracy: 0.5556 - val_auc: 0.8382 - val_loss: 0.2471 - val_precision: 1.0000 - val_recall: 0.1064 - learning_rate: 6.2500e-05\n",
            "Epoch 77: early stopping\n",
            "Restoring model weights from the end of the best epoch: 57.\n"
          ]
        }
      ],
      "source": [
        "# 3) Train\n",
        "history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b0baecc6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "THRESHOLD OPTIMIZATION & EVALUATION\n",
            "======================================================================\n",
            "\n",
            "Optimal threshold: 0.4582 (default=0.5)\n",
            "  At this threshold: TPR=0.9043, FPR=0.1368\n",
            "\n",
            "Results:\n",
            "  AUC-ROC: 0.8943\n",
            "  Accuracy (default threshold=0.5): 0.7884 (78.84%)\n",
            "  Accuracy (optimal threshold=0.4582): 0.8836 (88.36%)\n",
            "\n",
            "With optimal threshold:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Non-Planet     0.9011    0.8632    0.8817        95\n",
            "      Planet     0.8673    0.9043    0.8854        94\n",
            "\n",
            "    accuracy                         0.8836       189\n",
            "   macro avg     0.8842    0.8837    0.8836       189\n",
            "weighted avg     0.8843    0.8836    0.8836       189\n",
            "\n",
            "\n",
            "Prediction distribution (optimal threshold):\n",
            "  Predicted 0: 91\n",
            "  Predicted 1: 98\n",
            "True distribution:\n",
            "  True 0: 95\n",
            "  True 1: 94\n"
          ]
        }
      ],
      "source": [
        "# 4) Evaluate with optimal threshold\n",
        "y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a6e0f6da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VISUALIZATIONS\n",
            "======================================================================\n",
            "Saved: confusion_matrix_final.png\n",
            "Saved: training_history_final.png\n",
            "\n",
            "======================================================================\n",
            "PLOTTING LIGHTCURVES WITH PREDICTIONS (n=6)\n",
            "======================================================================\n",
            "Saved: sample_lightcurves_predictions.png\n",
            "\n",
            "======================================================================\n",
            "TRAINING COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Key improvements:\n",
            "  ✓ Perfectly balanced training data\n",
            "  ✓ Focal loss for hard examples\n",
            "  ✓ Optimal threshold selection\n",
            "  ✓ AUC-focused optimization\n",
            "\n",
            "Files:\n",
            "  - tess_model_final.keras\n",
            "  - best_model_final.keras\n",
            "  - optimal_threshold.npy\n",
            "  - confusion_matrix_final.png\n",
            "  - training_history_final.png\n",
            "  - sample_lightcurves_predictions.png\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Visualize & save artifacts\n",
        "plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "         X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "\n",
        "# Persist model and threshold\n",
        "model.save('tess_model_final.keras')\n",
        "np.save('optimal_threshold.npy', threshold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ✓ Perfectly balanced training data\")\n",
        "print(\"  ✓ Focal loss for hard examples\")\n",
        "print(\"  ✓ Optimal threshold selection\")\n",
        "print(\"  ✓ AUC-focused optimization\")\n",
        "print(\"\\nFiles:\")\n",
        "print(\"  - tess_model_final.keras\")\n",
        "print(\"  - best_model_final.keras\")\n",
        "print(\"  - optimal_threshold.npy\")\n",
        "print(\"  - confusion_matrix_final.png\")\n",
        "print(\"  - training_history_final.png\")\n",
        "print(\"  - sample_lightcurves_predictions.png\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797e9d45",
      "metadata": {},
      "source": [
        "## 11. (Optional) One-Click: Run Everything\n",
        "\n",
        "This cell wraps all steps into a single function for convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42f938a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    X_train, X_test, y_train, y_test, metadata_test, X_test_orig, X_err_test, scaler = load_data(\n",
        "        csv_path=CSV_PATH, n_bins=N_BINS\n",
        "    )\n",
        "    model = build_simple_cnn(n_bins=N_BINS)\n",
        "    history = train_model(model, X_train, y_train, X_test, y_test, epochs=200)\n",
        "    y_pred, y_pred_proba, threshold = evaluate_with_optimal_threshold(model, X_test, y_test)\n",
        "    plot_all(y_test, y_pred, y_pred_proba, history, metadata_test, X_test, threshold,\n",
        "             X_test_orig=X_test_orig, X_err_test=X_err_test, scaler=scaler)\n",
        "    model.save('tess_model_final.keras')\n",
        "    np.save('optimal_threshold.npy', threshold)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nKey improvements:\")\n",
        "    print(\"  ✓ Perfectly balanced training data\")\n",
        "    print(\"  ✓ Focal loss for hard examples\")\n",
        "    print(\"  ✓ Optimal threshold selection\")\n",
        "    print(\"  ✓ AUC-focused optimization\")\n",
        "    print(\"\\nFiles:\")\n",
        "    print(\"  - tess_model_final.keras\")\n",
        "    print(\"  - best_model_final.keras\")\n",
        "    print(\"  - optimal_threshold.npy\")\n",
        "    print(\"  - confusion_matrix_final.png\")\n",
        "    print(\"  - training_history_final.png\")\n",
        "    print(\"  - sample_lightcurves_predictions.png\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Uncomment to run end-to-end:\n",
        "# main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Interpreting Results & Next Steps\n",
        "\n",
        "- **AUC-ROC** is the primary score during training. Inspect training curves to ensure you’re not overfitting.  \n",
        "- **Confusion matrix** with counts and percentages helps quantify trade-offs at the **optimal threshold**.  \n",
        "- **False positives** vs **false negatives**: use domain needs to decide how to tune `alpha`/`gamma` in focal loss or to move the threshold.\n",
        "\n",
        "**Ideas to try next**\n",
        "\n",
        "- Add **class-dependent augmentations** (e.g., transit-like dips for positives).  \n",
        "- Calibrate probabilities (e.g., **Platt scaling**, **isotonic regression**) for better decision thresholds.  \n",
        "- Incorporate additional channels (centroid motion, background, etc.) into a **multi-input** model.  \n",
        "- Use **cross-validation** on the training set to measure variability across folds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Appendix: Notes on Data Schema\n",
        "\n",
        "- Ensure your CSV contains **exactly** `n_bins` columns named `flux_0000 .. flux_{n_bins-1:04d}` and matching `flux_err_*` columns.\n",
        "- Metadata columns are optional for training but used for prettier plots.\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "- `ValueError: columns not found`: your CSV headers don’t match the expected names. Check `n_bins` and column prefixes.  \n",
        "- `CUDA out of memory`: reduce `batch_size`, or limit GPU memory; try the provided GPU memory-growth snippet.  \n",
        "- `AUC not improving`: try a bigger `samples_per_class`, more dropout, or adjust `gamma`/`alpha`.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_TESS_Transit_Classification.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
