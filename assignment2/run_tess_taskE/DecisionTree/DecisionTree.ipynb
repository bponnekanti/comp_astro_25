{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21907ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, average_precision_score,\n",
    "    precision_score\n",
    ")\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a43ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path='tess_data.csv', n_bins=1000, use_scaler=False, samples_per_class=350):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Dataset: {df.shape[0]} samples\")\n",
    "    \n",
    "    flux_cols = [f'flux_{i:04d}' for i in range(n_bins)]\n",
    "    flux_err_cols = [f'flux_err_{i:04d}' for i in range(n_bins)]\n",
    "    X = df[flux_cols].values\n",
    "    X_err = df[flux_err_cols].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    metadata_cols = ['toi_name', 'tic', 'label', 'disp', 'period_d', 't0_bjd', 'dur_hr', 'sector']\n",
    "    metadata = df[metadata_cols]\n",
    "    \n",
    "    print(\"Original distribution:\")\n",
    "    print(f\"  Class 0: {(y==0).sum()}, Class 1: {(y==1).sum()}\")\n",
    "    if (y==0).sum() > 0:\n",
    "        print(f\"  Ratio: {(y==1).sum() / (y==0).sum():.2f}:1\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, X_err_train, X_err_test, idx_train, idx_test = train_test_split(\n",
    "        X, y, X_err, np.arange(len(y)),\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y\n",
    "    )\n",
    "    print(f\"Initial split - Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    \n",
    "    # Balance training set\n",
    "    X_train, y_train = create_balanced_dataset(X_train, y_train, samples_per_class=samples_per_class)\n",
    "    \n",
    "    scaler = None\n",
    "    if use_scaler:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STANDARDIZATION\")\n",
    "        print(\"=\"*70)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        print(f\"Train: mean={X_train.mean():.6f}, std={X_train.std():.6f}\")\n",
    "        print(f\"Test:  mean={X_test.mean():.6f}, std={X_test.std():.6f}\")\n",
    "    \n",
    "    metadata_test = metadata.iloc[idx_test].reset_index(drop=True)\n",
    "    print(f\"Final - X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "    print(f\"Train dist: 0={(y_train==0).sum()}, 1={(y_train==1).sum()}\")\n",
    "    \n",
    "    # Return X_test copy (for optional inverse transform plotting if scaler is used)\n",
    "    return X_train, X_test, y_train, y_test, metadata_test, X_test.copy(), X_err_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7754d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(X, y, samples_per_class=400):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING BALANCED DATASET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    X0 = X[y == 0]\n",
    "    X1 = X[y == 1]\n",
    "    print(f\"Original - Class 0: {len(X0)}, Class 1: {len(X1)}\")\n",
    "    \n",
    "    def augment_to_target(X_orig, n_target):\n",
    "        if len(X_orig) >= n_target:\n",
    "            idx = np.random.choice(len(X_orig), n_target, replace=False)\n",
    "            return X_orig[idx]\n",
    "        \n",
    "        X_result = [X_orig]\n",
    "        while len(np.vstack(X_result)) < n_target:\n",
    "            n_needed = n_target - len(np.vstack(X_result))\n",
    "            idx = np.random.choice(len(X_orig), min(len(X_orig), n_needed))\n",
    "            aug_type = np.random.rand()\n",
    "            if aug_type < 0.25:\n",
    "                X_aug = X_orig[idx] + np.random.normal(0, 0.01, (len(idx), X_orig.shape[1]))\n",
    "            elif aug_type < 0.5:\n",
    "                scale = 1.0 + np.random.uniform(-0.03, 0.03, (len(idx), 1))\n",
    "                X_aug = X_orig[idx] * scale\n",
    "            elif aug_type < 0.75:\n",
    "                shifts = np.random.randint(-20, 20, len(idx))\n",
    "                X_aug = np.array([np.roll(X_orig[i], s) for i, s in zip(idx, shifts)])\n",
    "            else:\n",
    "                X_aug = X_orig[idx] * (1.0 + np.random.uniform(-0.02, 0.02, (len(idx), 1)))\n",
    "                X_aug += np.random.normal(0, 0.008, X_aug.shape)\n",
    "            X_result.append(X_aug)\n",
    "        X_final = np.vstack(X_result)\n",
    "        return X_final[:n_target]\n",
    "    \n",
    "    X0_bal = augment_to_target(X0, samples_per_class)\n",
    "    X1_bal = augment_to_target(X1, samples_per_class)\n",
    "    print(f\"Balanced - Class 0: {len(X0_bal)}, Class 1: {len(X1_bal)}\")\n",
    "    \n",
    "    X_bal = np.vstack([X0_bal, X1_bal])\n",
    "    y_bal = np.concatenate([np.zeros(samples_per_class), np.ones(samples_per_class)])\n",
    "    \n",
    "    idx = np.arange(len(X_bal))\n",
    "    np.random.shuffle(idx)\n",
    "    return X_bal[idx], y_bal[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "605ae82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train,y_train,max_depth=None,min_samples_leaf=5):\n",
    "    model = DecisionTreeClassifier( \n",
    "        max_depth = max_depth,\n",
    "        min_samples_leaf = min_samples_leaf,\n",
    "        random_state = 42\n",
    "    )\n",
    "    if hasattr(model, 'oob_score_') and model.oob_score_ is not None:\n",
    "        print(f\"OOB Score: {model.oob_score_:.4f}\")    \n",
    "    model.fit(X_train,y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050aa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_optimal_threshold(model, X_test, y_test):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"THRESHOLD OPTIMIZATION & EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, proba)\n",
    "    j_scores = tpr - fpr\n",
    "    best_idx = np.argmax(j_scores)\n",
    "    best_thresh = thresholds[best_idx]\n",
    "    \n",
    "    y_pred_default = (proba >= 0.5).astype(int)\n",
    "    y_pred_best = (proba >= best_thresh).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    acc_default = accuracy_score(y_test, y_pred_default)\n",
    "    acc_best = accuracy_score(y_test, y_pred_best)\n",
    "    \n",
    "    print(f\"Optimal threshold: {best_thresh:.4f} (default=0.5)\")\n",
    "    print(f\"  At this threshold: TPR={tpr[best_idx]:.4f}, FPR={fpr[best_idx]:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"Accuracy @0.5: {acc_default:.4f} ({acc_default*100:.2f}%)\")\n",
    "    print(f\"Accuracy @{best_thresh:.4f}: {acc_best:.4f} ({acc_best*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nClassification report (optimal threshold):\")\n",
    "    print(classification_report(y_test, y_pred_best, target_names=['Non-Planet','Planet'], digits=4, zero_division=0))\n",
    "    \n",
    "    return y_pred_best, proba, best_thresh, (fpr, tpr, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c96a975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    precision =precision_score(y_test, y_pred, zero_division=0)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return cm, precision, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f4683ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(cm, precision, report, filename=\"report_decisiontree_assignment2_taskE.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Decision Tree Classifier Report\\n\")\n",
    "        f.write(\"======================================\\n\\n\")\n",
    "\n",
    "        f.write(\"Confusion Matrix:\\n\")\n",
    "        f.write(str(cm) + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"Precision:\\n\")\n",
    "        f.write(str(precision) + \"\\n\\n\")\n",
    "\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(report + \"\\n\")\n",
    "\n",
    "        f.write(\"\\n---\\n\")\n",
    "        f.write(\"Generated for assignment 2 Task E\\n\")\n",
    "    print(f\"âœ” Report saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d48aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_image(y_true, y_pred, threshold, save_path='confusion_matrix_DT.png'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = plt.gca()\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(2),\n",
    "           yticks=np.arange(2),\n",
    "           xticklabels=['Non-Planet', 'Planet'],\n",
    "           yticklabels=['Non-Planet', 'Planet'],\n",
    "           xlabel='Predicted', ylabel='True',\n",
    "           title=f'Confusion Matrix (threshold={threshold:.3f})')\n",
    "    total = cm.sum()\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count = cm[i, j]\n",
    "            pct = (count / total * 100) if total > 0 else 0.0\n",
    "            ax.text(j, i, f\"{count}\\n({pct:.1f}%)\", ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, proba, save_path='roc_curve_DT.png'):\n",
    "    fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "    auc = roc_auc_score(y_true, proba)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(fpr, tpr, linewidth=2)\n",
    "    ax.plot([0,1], [0,1], linestyle='--')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curve (AUC={auc:.4f})')\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_pr_curve(y_true, proba, save_path='pr_curve_DT.png'):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, proba)\n",
    "    ap = average_precision_score(y_true, proba)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(recall, precision, linewidth=2)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(f'Precision-Recall Curve (AP={ap:.4f})')\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_probability_histograms(y_true, proba, save_path='probability_hist_DT.png'):\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.hist(proba[y_true==0], bins=30, alpha=0.6, label='Non-Planet', density=True)\n",
    "    ax.hist(proba[y_true==1], bins=30, alpha=0.6, label='Planet', density=True)\n",
    "    ax.set_xlabel('Predicted Probability (class=1)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Predicted Probability Distributions by Class')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_lightcurve_sample(idx, X_test_standardized, X_err_test, metadata_test, scaler=None, proba=None, y_true=None, y_pred=None, save_prefix='sample_lightcurve_RF'):\n",
    "    # Make a single-figure plot for one sample (no subplots)\n",
    "    x_std = X_test_standardized[idx].reshape(1, -1)\n",
    "    if scaler is not None:\n",
    "        x_orig = scaler.inverse_transform(x_std).flatten()\n",
    "        yerr = X_err_test[idx]\n",
    "    else:\n",
    "        x_orig = x_std.flatten()\n",
    "        yerr = X_err_test[idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = plt.gca()\n",
    "    ax.errorbar(np.arange(len(x_orig)), x_orig, yerr=yerr, fmt='o', markersize=2, alpha=0.6)\n",
    "    ax.axhline(np.median(x_orig), linestyle='--', linewidth=1)\n",
    "    ax.set_xlabel('Time Bin')\n",
    "    ax.set_ylabel('Flux')\n",
    "    \n",
    "    toi = metadata_test.loc[idx, 'toi_name']\n",
    "    tic = metadata_test.loc[idx, 'tic']\n",
    "    disp = metadata_test.loc[idx, 'disp']\n",
    "    sector = metadata_test.loc[idx, 'sector']\n",
    "    \n",
    "    tstr = f'TOI {toi} (TIC {tic}, {disp}) - Sector {sector}'\n",
    "    if proba is not None and y_true is not None and y_pred is not None:\n",
    "        pred_str = 'Transit' if y_pred[idx]==1 else 'Non-Transit'\n",
    "        true_str = 'Transit' if y_true[idx]==1 else 'Non-Transit'\n",
    "        tstr += f'\\nTrue: {true_str} | Pred: {pred_str} (p={proba[idx]:.3f})'\n",
    "    \n",
    "    ax.set_title(tstr)\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    path = f\"{save_prefix}_{idx}.png\"\n",
    "    plt.savefig(path, dpi=300)\n",
    "    print(f\"Saved: {path}\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6979d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'tess_data.csv'    # change if needed\n",
    "N_BINS = 1000\n",
    "USE_SCALER = False                  # Random Forest doesn't need scaling; set True if you want comparability\n",
    "SAMPLES_PER_CLASS = 350  \n",
    "RANDOM_STATE=42# per-class size after augmentation (train split only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1eed8a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "Dataset: 944 samples\n",
      "Original distribution:\n",
      "  Class 0: 472, Class 1: 472\n",
      "  Ratio: 1.00:1\n",
      "Initial split - Train: 755, Test: 189\n",
      "\n",
      "======================================================================\n",
      "CREATING BALANCED DATASET\n",
      "======================================================================\n",
      "Original - Class 0: 377, Class 1: 378\n",
      "Balanced - Class 0: 350, Class 1: 350\n",
      "Final - X_train: (700, 1000), X_test: (189, 1000)\n",
      "Train dist: 0=350, 1=350\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, metadata_test, X_test_std_copy, X_err_test, scaler = load_data(\n",
    "    csv_path=CSV_PATH, n_bins=N_BINS, use_scaler=USE_SCALER, samples_per_class=SAMPLES_PER_CLASS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c422aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = train_decision_tree(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53dcb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm,precision,report = evaluate_model(DT,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc1d9891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73 22]\n",
      " [30 64]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cd5a3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "THRESHOLD OPTIMIZATION & EVALUATION\n",
      "======================================================================\n",
      "Optimal threshold: 0.2000 (default=0.5)\n",
      "  At this threshold: TPR=0.7553, FPR=0.2632\n",
      "AUC-ROC: 0.7407\n",
      "Accuracy @0.5: 0.7249 (72.49%)\n",
      "Accuracy @0.2000: 0.7460 (74.60%)\n",
      "\n",
      "Classification report (optimal threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non-Planet     0.7527    0.7368    0.7447        95\n",
      "      Planet     0.7396    0.7553    0.7474        94\n",
      "\n",
      "    accuracy                         0.7460       189\n",
      "   macro avg     0.7461    0.7461    0.7460       189\n",
      "weighted avg     0.7462    0.7460    0.7460       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_opt, proba_test, best_thresh, roc_tuple = evaluate_with_optimal_threshold(DT, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cea01f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: confusion_matrix_DT.png\n",
      "Saved: roc_curve_DT.png\n",
      "Saved: pr_curve_DT.png\n",
      "Saved: probability_hist_DT.png\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix_image(y_test, y_pred_opt, best_thresh, save_path='confusion_matrix_DT.png')\n",
    "plot_roc_curve(y_test, proba_test, save_path='roc_curve_DT.png')\n",
    "plot_pr_curve(y_test, proba_test, save_path='pr_curve_DT.png')\n",
    "plot_probability_histograms(y_test, proba_test, save_path='probability_hist_DT.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc02e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdcef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70ebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
